{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pedestrian Detection with SVM (Support Vector Machines)",
   "id": "4c412a3c228aa37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 游눹 **Used Libraries**",
   "id": "37986e402e1ff167"
  },
  {
   "cell_type": "markdown",
   "id": "-mjNbOFRE6nq",
   "metadata": {
    "id": "-mjNbOFRE6nq"
   },
   "source": [
    "- **glob:** This library is used to find all files that match a specified pattern. In your case, it might be used to find and load images of pedestrians and non-pedestrians from one or more directories.\n",
    "\n",
    "- **os:** The os library is essential for interacting with the operating system. It can be used to manipulate file paths, create directories, check the existence of files, etc. In your code, it is probably used for file-related operations, such as reading image files.\n",
    "\n",
    "- **tarfile:** This library provides operations for tar files, which are commonly used to compress files and directories on Unix systems. You might be using this to extract images from a compressed tar file containing your datasets.\n",
    "\n",
    "- **cv2:** OpenCV is a popular library for computer vision and image processing. You are likely using it to load and preprocess images, such as resizing, converting to grayscale, or applying other filters needed for feature extraction.\n",
    "\n",
    "- **matplotlib:** This library is commonly used for data visualization in Python. In your code, it might be used to display images and plots, which can be useful for data exploration and result evaluation.\n",
    "\n",
    "- **numpy:** NumPy is a fundamental library for numerical computing in Python. It is used to perform mathematical operations on arrays and multidimensional arrays. In the context of your code, it might be used to manipulate and process image data.\n",
    "\n",
    "- **requests:** This library allows you to make HTTP requests in Python. In your code, it might be used to download images from a URL if your data is hosted online.\n",
    "\n",
    "- **seaborn:** Seaborn is a data visualization library based on matplotlib. It is used to create attractive and informative statistical graphics. In your code, it might be used to visualize the confusion matrix or other graphs related to model evaluation.\n",
    "\n",
    "- **skimage:** This library provides a collection of algorithms for image processing. In particular, the skimage.feature module provides tools for feature extraction, such as the Histogram of Oriented Gradients (HOG), which is useful in object detection in images.\n",
    "\n",
    "- **scikit-learn:** Scikit-learn is a machine learning library in Python that provides efficient implementations of a wide range of machine learning algorithms. In your code, you are using sklearn.svm to train a support vector machine (SVM) model for pedestrian detection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TVv-VIKPzNOD",
   "metadata": {
    "id": "TVv-VIKPzNOD"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn-intelex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d23947",
   "metadata": {
    "id": "70d23947"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.259497Z",
     "start_time": "2024-05-14T03:52:33.379714Z"
    },
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tarfile\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from skimage.feature import hog\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Estas librer칤as son para optimizar la librer칤a de sklearnex cuando \n",
    "# from sklearnex import patch_sklearn \n",
    "# patch_sklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2869b0347313e89",
   "metadata": {
    "id": "c2869b0347313e89"
   },
   "source": [
    "## 游 **Loading the Dataset**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbf878b6ed738f",
   "metadata": {
    "id": "6edbf878b6ed738f"
   },
   "source": "The dataset was obtained from: http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Daimler_Mono_Ped__Class__Bench/daimler_mono_ped__class__bench.html. It contains images of pedestrians and non-pedestrians, which will be very useful for training our model. Since the dataset comes in .tar.gz format, the following function downloads it directly from the URL and extracts the images into the specified folder."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe889c0cda6961ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.306494Z",
     "start_time": "2024-05-14T03:52:35.292497Z"
    },
    "id": "fe889c0cda6961ab"
   },
   "outputs": [],
   "source": [
    "def download_and_extract_dataset(url: str, target_dir: str):\n",
    "    \"\"\"\n",
    "    Descarga y extrae un conjunto de datos en formato tar.gz desde una URL en el directorio especificado.\n",
    "\n",
    "    Args:\n",
    "        url (str): La URL de donde se descargar치 el conjunto de datos.\n",
    "        target_dir (str): El directorio donde se guardar치 el conjunto de datos.\n",
    "    \"\"\"\n",
    "    # Revisar que el directorio objetivo existe\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "    # Establece la ruta donde se guardar치 el conjunto de datos\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    file_path = os.path.join(target_dir, filename)\n",
    "\n",
    "    # Verifica si el archivo ya existe\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Descargando el conjunto de datos...\")\n",
    "        # Env칤a una solicitud GET a la URL\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            # Guarda el archivo en fragmentos para evitar usar demasiada memoria\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(\"Descarga completa. Extrayendo archivos...\")\n",
    "            # Extrae el archivo tar.gz\n",
    "            with tarfile.open(file_path, \"r:gz\") as tar:\n",
    "                tar.extractall(path=target_dir)\n",
    "            print(\"Extracci칩n completa.\")\n",
    "        else:\n",
    "            print(\"Fallo al descargar el archivo. C칩digo de estado:\", response.status_code)\n",
    "    else:\n",
    "        print(\"El conjunto de datos ya existe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7WT6dgsD0Ny5",
   "metadata": {
    "id": "7WT6dgsD0Ny5"
   },
   "source": "Function Execution"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7dc0f5beec69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.322497Z",
     "start_time": "2024-05-14T03:52:35.308494Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afe7dc0f5beec69c",
    "outputId": "9b3374d6-beb1-416f-d4b4-bf3af124f167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando el conjunto de datos...\n",
      "Descarga completa. Extrayendo archivos...\n",
      "Extracci칩n completa.\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"http://www.lookingatpeople.com/data/Daimler/pami06-munder-gavrila/DC-ped-dataset_base.tar.gz\"\n",
    "dataset_target_dir = \"data/pedestrians\"\n",
    "\n",
    "download_and_extract_dataset(dataset_url, dataset_target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c46e8f2f73f7c8",
   "metadata": {
    "id": "c2c46e8f2f73f7c8"
   },
   "source": [
    "# 游닇 **Training and Testing Data**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a1f9204bea8460",
   "metadata": {
    "id": "e4a1f9204bea8460"
   },
   "source": [
    "According to the dataset description found on the following page: http://www.lookingatpeople.com/data/Daimler/pami06-munder-gavrila/README_benchmark.txt, the dataset has the following structure:\n",
    "\n",
    "| **Dataset Name** | **Purpose** | **Pedestrian Labels** | **Pedestrian Examples** | **Non-ped. Examples** | **Storage Size** |\n",
    "|------------------|-------------|-----------------------|-------------------------|-----------------------|------------------|\n",
    "| 1                | Training    | 800                   | 4800                    | 5000                  | 39 MB            |\n",
    "| 2                | Training    | 800                   | 4800                    | 5000                  | 39 MB            |\n",
    "| 3                | Training    | 800                   | 4800                    | 5000                  | 39 MB            |\n",
    "| T1               | Test        | 800                   | 4800                    | 5000                  | 39 MB            |\n",
    "| T2               | Test        | 800                   | 4800                    | 5000                  | 39 MB            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U-__SCQwFsTl",
   "metadata": {
    "id": "U-__SCQwFsTl"
   },
   "source": [
    "We obtain our data and will explain a bit about the function.\n",
    "\n",
    "This function called `get_data_files` is responsible for obtaining a list of data files based on certain parameters it receives as input. Let's look at the details:\n",
    "\n",
    "- **sub_dir:** This parameter is a string that represents the subdirectory where the data files will be searched. It is the specific directory where the relevant files are expected to be found.\n",
    "\n",
    "- **sub_dirs:** This parameter is a list of strings that contains the names of the subdirectories within `sub_dir` where the data files will be searched. This allows searching in multiple subdirectories within `sub_dir` simultaneously.\n",
    "\n",
    "- **file_extension:** This parameter is a string that specifies the file extension of the files being searched for. By default, it is set to 'pgm'.\n",
    "\n",
    "The function uses the `glob` library to perform the file search in the file system. Basically, `glob.glob()` returns a list of filenames that match a specified pattern.\n",
    "\n",
    "Inside the function, an empty list called `data` is initialized, which will be used to store the names of the files found.\n",
    "\n",
    "Then, it iterates over each `sub_dir` in `sub_dirs`. For each `sub_dir`, `glob.glob()` is used to find all files with the specified extension `(file_extension)` within the corresponding subdirectory. These filenames are stored in the variable `data_files`.\n",
    "\n",
    "Finally, the filenames found in `data_files` are added to the `data` list using the `extend()` method, which allows adding multiple elements to a list.\n",
    "\n",
    "The function returns the `data` list, which contains the names of all the files found in the specified subdirectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40609272a7e540df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.338494Z",
     "start_time": "2024-05-14T03:52:35.325498Z"
    },
    "id": "40609272a7e540df"
   },
   "outputs": [],
   "source": [
    "def get_data_files(sub_dir: str, sub_dirs: str, file_extension: str='pgm') -> list:\n",
    "    data = []\n",
    "    for sub_dir in sub_dirs:\n",
    "        data_files = glob.glob(f\"{dataset_target_dir}/{sub_dir}/*.{file_extension}\")\n",
    "        data.extend(data_files)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f63778b6c90809b",
   "metadata": {
    "id": "3f63778b6c90809b"
   },
   "source": [
    "## **Training Data**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gksCLyqSHBog",
   "metadata": {
    "id": "gksCLyqSHBog"
   },
   "source": [
    "Training files for the pedestrian class `(pedestrians)`.\n",
    "\n",
    "- **train_pedestrians_sub_dirs:** This is a list containing the names of the subdirectories where the pedestrian examples are located within the training dataset. Each subdirectory name is in the format `\"number/ped_examples\"`, which suggests that the pedestrian examples are organized in numbered subdirectories.\n",
    "\n",
    "- **train_pedestrians:** This line of code calls the `get_data_files()` function. It passes the main dataset directory `(dataset_target_dir)` and the list of pedestrian subdirectories `(train_pedestrians_sub_dirs)`. This function returns a list containing the names of all pedestrian example files found in the specified subdirectories.\n",
    "\n",
    "- **len(train_pedestrians):** This simply calculates the length of the `train_pedestrians` list, i.e., the total number of pedestrian example files found in the specified subdirectories.\n",
    "\n",
    "For this particular case, we have 14,400 pedestrians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9ef6981f7f8746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.510497Z",
     "start_time": "2024-05-14T03:52:35.341498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b9ef6981f7f8746",
    "outputId": "c8c80c38-c55b-4bf4-a5b2-71c6f0072e63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pedestrians_sub_dirs = [\"1/ped_examples\", \"2/ped_examples\", \"3/ped_examples\"]\n",
    "train_pedestrians = get_data_files(dataset_target_dir, train_pedestrians_sub_dirs)\n",
    "len(train_pedestrians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CJ_-DqgSHb5u",
   "metadata": {
    "id": "CJ_-DqgSHb5u"
   },
   "source": [
    "For this other case, it works similarly:\n",
    "\n",
    "- **train_non_pedestrians_sub_dirs:** Similar to the previous case, this is a list containing the names of the subdirectories where the `non-pedestrian` examples are located within the training dataset.\n",
    "\n",
    "- **train_non_pedestrians:** As before, this line calls the `get_data_files()` function with the main dataset directory and the list of non-pedestrian subdirectories. This function returns a list containing the names of all non-pedestrian example files found in the specified subdirectories.\n",
    "\n",
    "- **len(train_non_pedestrians):** Again, this calculates the length of the `train_non_pedestrians` list, i.e., the total number of non-pedestrian example files found in the specified subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9786c27512d65f4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.651494Z",
     "start_time": "2024-05-14T03:52:35.513498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9786c27512d65f4f",
    "outputId": "d9221763-382d-48ac-9187-c50b9526d300"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_non_pedestrians_sub_dirs = [\"1/non-ped_examples\", \"2/non-ped_examples\", \"3/non-ped_examples\"]\n",
    "train_non_pedestrians = get_data_files(dataset_target_dir, train_non_pedestrians_sub_dirs)\n",
    "len(train_non_pedestrians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30ee783949cb71",
   "metadata": {
    "id": "df30ee783949cb71"
   },
   "source": [
    "## **Testing Data**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f49258b1190ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.747495Z",
     "start_time": "2024-05-14T03:52:35.653498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e98f49258b1190ed",
    "outputId": "ab0be7de-bf10-4e57-d571-0d434eb3a176"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pedestrians_sub_dirs = [\"T1/ped_examples\", \"T2/ped_examples\"]\n",
    "test_pedestrians = get_data_files(dataset_target_dir, test_pedestrians_sub_dirs)\n",
    "len(test_pedestrians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5742dc2f4329f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:35.842509Z",
     "start_time": "2024-05-14T03:52:35.749496Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e5742dc2f4329f5",
    "outputId": "ed56f213-68ee-4ff9-9de5-9d7d23dfdd1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_non_pedestrians_sub_dirs = [\"T1/non-ped_examples\", \"T2/non-ped_examples\"]\n",
    "test_non_pedestrians = get_data_files(dataset_target_dir, test_non_pedestrians_sub_dirs)\n",
    "len(test_non_pedestrians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b58f98001502d",
   "metadata": {
    "id": "6e7b58f98001502d"
   },
   "source": [
    "# 游녭 **Calculation of HOG on a Single Image**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306e49cc57e3e7",
   "metadata": {
    "id": "c306e49cc57e3e7"
   },
   "source": [
    "Visualization of a single pedestrian image using `cv2`, detailed below:\n",
    "\n",
    "- `cv2.imread(train_pedestrians[170], cv2.COLOR_BGR2GRAY)`: Uses the `cv2.imread()` function from **OpenCV** to read an image from the pedestrian training dataset. `train_pedestrians[170]` provides the file path of the specific image to be loaded. Additionally, `cv2.COLOR_BGR2GRAY` is specified as the second argument, indicating that the image will be loaded in grayscale. This means the image will be converted to a single-layer representation `(grayscale)` instead of a color image. The result is stored in the variable `img_pedestrian`.\n",
    "\n",
    "- `plt.imshow(img_pedestrian, cmap='gray')`: Uses the `plt.imshow()` function from **Matplotlib** to display the loaded image. `img_pedestrian` is the image to be displayed. `cmap='gray'` is specified to indicate that the image should be displayed in grayscale. This ensures that the image is shown correctly, as it was loaded in grayscale in the previous step.\n",
    "\n",
    "- `plt.show()`: This line displays the image in a viewing window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811958d9465dd51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:36.096106Z",
     "start_time": "2024-05-14T03:52:35.844494Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "7811958d9465dd51",
    "outputId": "554f52ae-bc5b-44b2-ab94-69051aca5e27"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOgAAAGdCAYAAAAYMT++AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiTElEQVR4nO3df1DUdf4H8Ccgu6DA6oKwrPzwF2pqUENJXOVYciLNOJrejf2YOewamxpsRrl+DDOV1dXQj5lvVkN4M1daM6HVXdqPu7SiwJrEKy5PrYuEKPBwUTF2AWVB9vP9w2NrU9jXB5fjJTwfMzsjuy8/n/dnlyef/fHa9zvMMAwDRKRS+EgPgIgGxoASKcaAEinGgBIpxoASKcaAEinGgBIpxoASKTZupAfwSz6fDy0tLYiNjUVYWNhID4co5AzDQEdHB5xOJ8LDBz9HqgtoS0sLUlNTR3oYRMOuubkZKSkpg9YMW0DLysrw9NNPw+VyISsrC88//zwWLFgQ9P/FxsYCANLS0oL+dTlz5ox4PP3bDWbcONldkpCQIKqLiooS1QHAhAkTRHV9fX2iuoiICFFdZ2enqA4AvvrqK1FdT0+PqK63t1e878svv1xUF+yXvp/0GZrP5xPVAcCpU6eC1vT29uKtt94S/U4OS0Bfe+01FBcXY/PmzcjJycGmTZuQn5+Puro6JCYmDvp/+++08PDwoAENdvvPSX9ZpXXSIEdGRorqzNRKj1t6LGbGKN13qOsA+X1usVhEdcMRUDN/cCT7H5Y3if7v//4Pa9euxW233Ya5c+di8+bNGD9+PF566aXh2B3RqBXygPb09KC2thZ5eXk/7SQ8HHl5edi7d+859V6vFx6PJ+BCRGeFPKAnTpxAX18fkpKSAq5PSkqCy+U6p760tBQ2m81/4RtERD8Z8c9BS0pK4Ha7/Zfm5uaRHhKRGiF/kyghIQERERFobW0NuL61tRUOh+OceqvVCqvVGuphEI0KIT+DWiwWZGdno7Ky0n+dz+dDZWUlcnNzQ707olFtWD5mKS4uRmFhIa644gosWLAAmzZtQldXF2677baQ7kf6tvtwbFN61h+OjzCkn+lGR0eL6mJiYkR1wNk39SS+//57UZ2Zz2Cln62e772OC9memWd4kvvczMc2wxLQ1atX4/jx43jooYfgcrlw2WWXYdeuXee8cUREgxu2TqJ169Zh3bp1w7V5ojFhxN/FJaKBMaBEijGgRIoxoESKMaBEijGgRIoxoESKMaBEiqmbk6if1+sN2vomnSIEkLdrhfrb+GamZenu7hbVSb+SJ20zNLPA3cSJE0V1kyZNEtVJ728AcLvdojrp8Zw+fVpUZ2baGkmtmfubZ1AixRhQIsUYUCLFGFAixRhQIsUYUCLFGFAixRhQIsUYUCLFLupOIjOTXYV6KUPp5Flm1uqQ+uWUpgOx2+2iOmmHDgB0dHSI6qT3j3TiLsBcV5aE9HfCzMRvku42M8fMMyiRYgwokWIMKJFiDCiRYgwokWIMKJFiDCiRYgwokWIMKJFiajuJIiMjg3YSSefHAeRdI9IOGCkzc+5IlwuUOnnypKhOuuwhIF+eUTonUUREhHjfx48fF9VJO3WkvxNTp04V1QGy7i0zv2M8gxIpxoASKcaAEinGgBIpxoASKcaAEinGgBIpxoASKcaAEimmtpNo0qRJQbtMkpKSxNtrb28X1YV6DiEz88/YbDZRnXQVNGknkZk5d6TzAkm7b6RzHAFAV1eXqE76WEtXGWtoaBDVAbLVzcz8jvEMSqRYyAP68MMPIywsLOAyZ86cUO+GaEwYlqe48+bNw4cffvjTToQN1kQUaFiSM27cODgcjuHYNNGYMiyvQQ8fPgyn04np06fj1ltvRVNT04C1Xq8XHo8n4EJEZ4U8oDk5Odi6dSt27dqF8vJyNDY24tprrx3w3brS0lLYbDb/JTU1NdRDIrpohTygBQUF+O1vf4vMzEzk5+fj73//O9rb2/H666+ft76kpARut9t/aW5uDvWQiC5aw/7uzcSJEzFr1izU19ef93ar1Qqr1TrcwyC6KA3756CdnZ1oaGhAcnLycO+KaNQJeUDvueceVFdX4/vvv8dnn32GG2+8EREREbj55ptDvSuiUS/kT3GPHDmCm2++GW1tbZg8eTKuueYa1NTUYPLkyaa2Y7Vag7b6mWmZ6uvrE9VJ27+k7XZmWv2kpNuUjvHyyy8X71vadCKd0O306dPifUsnIvvkk09EddJlF10ul6gOAGbMmBG0xszvbcgDun379lBvkmjMYi8ukWIMKJFiDCiRYgwokWIMKJFiDCiRYgwokWIMKJFiaqc66OnpCdpJdOrUKfH2Qj0ZmHTpOjPGjx8vqpNO8pWdnS2qW7RokagOkB+3tNvJTCeRdFK1WbNmieq++eYbUV1sbKyoDjg7m0gwXq8Xb7/9tmh7PIMSKcaAEinGgBIpxoASKcaAEinGgBIpxoASKcaAEinGgBIppraTKCoqKmgnkZnpOqOjo0V1l112majO6XSK6qTz3gDAt99+K6qTrnWTnp4uqpN26ABAa2trSOt++OEH8b6l3WDSOovFIqqbMmWKqA6QdVqZ6ULjGZRIMQaUSDEGlEgxBpRIMQaUSDEGlEgxBpRIMQaUSDEGlEgxtZ1EVqs1aMfM1KlTxdu75ZZbRHVXXXWVqC5Yl1O/d955R1QHyOfIycjIENUlJSWJ6qQrugFAW1ubqK6xsVFUZ2blMGkHjmSFMQDIy8sT1f373/8W1QHAjz/+GLTG6/WKt8czKJFiDCiRYgwokWIMKJFiDCiRYgwokWIMKJFiDCiRYgwokWIMKJFialv9YmJigi6zd+2114q3d/XVV4vqpBNySZfXO3HihKjODGmrWGJioqjOzDKO0snAmpqaRHXd3d3ifUdFRYV0mxMnThTVpaWlieoA4NixY0FrzLRW8gxKpJjpgO7ZswfLli2D0+lEWFgYdu7cGXC7YRh46KGHkJycjOjoaOTl5eHw4cOhGi/RmGI6oF1dXcjKykJZWdl5b3/qqafw3HPPYfPmzdi3bx8mTJiA/Px8U09liOgs069BCwoKUFBQcN7bDMPApk2b8MADD2D58uUAgFdeeQVJSUnYuXMnbrrppnP+j9frDXhN5fF4zA6JaNQK6WvQxsZGuFyugO/Z2Ww25OTkYO/evef9P6WlpbDZbP5LampqKIdEdFELaUD7v3z7yy8KJyUlDfjF3JKSErjdbv+lubk5lEMiuqiN+McsVqvV1BorRGNJSM+gDocDwLmflbW2tvpvIyK5kAZ02rRpcDgcqKys9F/n8Xiwb98+5ObmhnJXRGOC6ae4nZ2dqK+v9//c2NiI/fv3w263Iy0tDevXr8djjz2GjIwMTJs2DQ8++CCcTidWrFhhaj9xcXFBO4mysrLE25N2CEkFG1s/6SRkAHDkyBFRnfQlgbSLycwSgNIxmulOkjpz5oyoTvo+Rmdnp6hOOkEcAEyYMCFojbQLDRhCQL/44gtcd911/p+Li4sBAIWFhdi6dSvuu+8+dHV14Y477kB7ezuuueYa7Nq1S9ymRUQ/MR3QRYsWDdpLGBYWhkcffRSPPvroBQ2MiNiLS6QaA0qkGANKpBgDSqQYA0qkGANKpBgDSqTYiDfLDyQjIyNox8zkyZP/R6M516uvviqqky4VCMi7k6THfejQIVHdwYMHRXUAcPLkSVGdtDFlOB5D6XxI//nPf0R1ZppspkyZErSmt7dXvD2eQYkUY0CJFGNAiRRjQIkUY0CJFGNAiRRjQIkUY0CJFGNAiRRjQIkUU9vq53A4EB0dPWjN559/Lt6etOWuo6NDVPerX/1KVPf222+L6gAgPj5eVHf8+HFRXUtLi6jOzBKJ4eGyv+l2u11UJ50IDACOHj0qqpMuzyg9FjPzNkuO28ykYTyDEinGgBIpxoASKcaAEinGgBIpxoASKcaAEinGgBIpxoASKaa2kygmJgbjx48ftGbv3r3i7X399deiuokTJ4rqbrjhBlGdmQmiPB6PqO67774T1R0+fFhUJ+28AYBJkyaJ6rq7u0V10mMG5EsaWiwWUZ20k8jM8oOSZS59Pp94ezyDEinGgBIpxoASKcaAEinGgBIpxoASKcaAEinGgBIpxoASKaa2kyguLi5oJ9GNN94o3t6sWbNEdTabTbxNiZUrV4prn3zySVGddFnB9vZ2UZ20ewqQd9VI6+Li4sT7DjZHVb/rrrtOVNfX1yeq+9vf/iaqA4BPPvkkZPsFeAYlUs10QPfs2YNly5bB6XQiLCwMO3fuDLh9zZo1CAsLC7gsXbo0VOMlGlNMB7SrqwtZWVkoKysbsGbp0qU4evSo/7Jt27YLGiTRWGX6NWhBQQEKCgoGrbFarXA4HEMeFBGdNSyvQauqqpCYmIjZs2fjrrvuQltb24C1Xq8XHo8n4EJEZ4U8oEuXLsUrr7yCyspKPPnkk6iurkZBQcGA71yVlpbCZrP5L6mpqaEeEtFFK+Qfs9x0003+f1966aXIzMzEjBkzUFVVhcWLF59TX1JSguLiYv/PHo+HISX6r2H/mGX69OlISEhAfX39eW+3Wq2Ii4sLuBDRWcMe0CNHjqCtrQ3JycnDvSuiUcf0U9zOzs6As2FjYyP2798Pu90Ou92ORx55BKtWrYLD4UBDQwPuu+8+zJw5E/n5+ab2ExEREbQbpbW1Vby9sLAwUd3cuXNFdV1dXaK6v/71r6I6ADh48KCoLtQdQjExMaI6QD7fj3TVMuk8Q4B85Tlpx9HUqVNFddu3bxfVAcCxY8eC1hiGId6e6YB+8cUXAa1U/a8fCwsLUV5ejgMHDuDll19Ge3s7nE4nlixZgj/+8Y+mlnAjorNMB3TRokWD/gXYvXv3BQ2IiH7CXlwixRhQIsUYUCLFGFAixRhQIsUYUCLFGFAixRhQIsXUThrW0NCAqKioQWuky8cBwIEDB0R1VVVVorrOzk5R3ZdffimqA4ATJ06I6iRL3AHyZQXNTGLV09MT0rrTp0+L9y1tH/zss89EdUeOHBHVmRmjZGlBM61+PIMSKcaAEinGgBIpxoASKcaAEinGgBIpxoASKcaAEinGgBIppraT6Ntvvw06QVVvb694e5LJnAD5hFzD0aUjnbepu7tbVCftvDFzP0r3LemoAeSTuZlx/PhxUZ30d0I6WRkgm0yOnUREowQDSqQYA0qkGANKpBgDSqQYA0qkGANKpBgDSqQYA0qkmNpOotmzZwddRi7YnEU/980334jq9u7dK6qTdhKZWRfV4XCI6g4fPiyqO3nypKjOTLdTqEm7nQB5p5V02UVp15h0fiVAdl+yk4holGBAiRRjQIkUY0CJFGNAiRRjQIkUY0CJFGNAiRRjQIkUY0CJFFPb6ldRUYGIiIhBa+x2u3h70jYxadubdAlAMxNySVvPpBN3SdsRJRNd9ZO2qQWb8G0opC13H374YUj3a6Yd0Uwbn4SpM2hpaSmuvPJKxMbGIjExEStWrEBdXV1ATXd3N4qKihAfH4+YmBisWrUKra2tIR000VhhKqDV1dUoKipCTU0NPvjgA/T29mLJkiUBf4E3bNiAd955B2+88Qaqq6vR0tKClStXhnzgRGOBqae4u3btCvh569atSExMRG1tLRYuXAi3240XX3wRFRUVuP766wEAW7ZswSWXXIKamhpcddVVoRs50RhwQW8Sud1uAD+9FqytrUVvby/y8vL8NXPmzEFaWtqAX+Pyer3weDwBFyI6a8gB9fl8WL9+Pa6++mrMnz8fAOByuWCxWM75Pl5SUhJcLtd5t1NaWgqbzea/pKamDnVIRKPOkANaVFSEQ4cOYfv27Rc0gJKSErjdbv+lubn5grZHNJoM6WOWdevW4d1338WePXuQkpLiv97hcKCnpwft7e0BZ9HW1tYBZwuwWq3ij0CIxhpTZ1DDMLBu3Trs2LEDH330EaZNmxZwe3Z2NiIjI1FZWem/rq6uDk1NTcjNzQ3NiInGEFNn0KKiIlRUVOCtt95CbGys/3WlzWZDdHQ0bDYbbr/9dhQXF8NutyMuLg533303cnNz+Q4u0RCEGSZaHwZaKm7Lli1Ys2YNgLONCn/4wx+wbds2eL1e5Ofn44UXXhBPiOXxeGCz2ZCQkIDw8MFP8GlpadKhIyMjQ1Qn7eaRki6FBwCdnZ2iOmknkbTzxky3k3SiNpvNJqqTdmQBCPr70E+69OH3338vqjPTaWXmvnS73YiLixu0xtQZVJLlqKgolJWVoayszMymieg82CxPpBgDSqQYA0qkGANKpBgDSqQYA0qkGANKpBgDSqSY2jmJfvOb3wRtojfTZC/tBpF26YR6e0Do57MZqPPrlyZMmCDeZkxMTEi3aaZL5/LLLxfVSdtKpR1HzzzzjKgOkHUnGYYhfqx5BiVSjAElUowBJVKMASVSjAElUowBJVKMASVSjAElUowBJVJMbSdRZmYmoqOjB60x03nz3Xffiep++OEHUZ10BnxptwqAoKu59UtPTxfVSVdqMzMPk3TVMum+zZB2MZ06dUpUJ30MzcybFGo8gxIpxoASKcaAEinGgBIpxoASKcaAEinGgBIpxoASKcaAEinGgBIpprbVz+VyBV3qzkyrn3RpP2lbV7Bl48zWAfLjmT59uqjuxx9/FNWZWTJP2o4obfUzc/9IlzSUTkT2/vvvi+qamppEdYBsiUTDMMT3D8+gRIoxoESKMaBEijGgRIoxoESKMaBEijGgRIoxoESKMaBEiqntJGptbQ26vKCZDhjpMoDSJfukHTVmlh+UHo+0s0U6RukxA/JlBaWTpZ05c0a8b2mn1eTJk0V1ubm5orq2tjZRHSDrYvL5fGhtbRVtj2dQIsVMBbS0tBRXXnklYmNjkZiYiBUrVqCuri6gZtGiRQgLCwu43HnnnSEdNNFYYSqg1dXVKCoqQk1NDT744AP09vZiyZIl55zW165di6NHj/ovTz31VEgHTTRWmHoNumvXroCft27disTERNTW1mLhwoX+68ePHw+HwyHaptfrhdfr9f8snUyYaCy4oNegbrcbAGC32wOuf/XVV5GQkID58+ejpKRk0Jm+S0tLYbPZ/JfU1NQLGRLRqDLkd3F9Ph/Wr1+Pq6++GvPnz/dff8sttyA9PR1OpxMHDhzA/fffj7q6Orz55pvn3U5JSQmKi4v9P3s8HoaU6L+GHNCioiIcOnQIn376acD1d9xxh//fl156KZKTk7F48WI0NDRgxowZ52zHarUG/TiFaKwa0lPcdevW4d1338XHH3+MlJSUQWtzcnIAAPX19UPZFdGYZuoMahgG7r77buzYsQNVVVWYNm1a0P+zf/9+AEBycvKQBkg0lpkKaFFRESoqKvDWW28hNjYWLpcLwNm5YqKjo9HQ0ICKigrccMMNiI+Px4EDB7BhwwYsXLgQmZmZpgZ25ZVXYvz48YPWmFniTjpPzS8/1x1Ic3OzqC4yMlJUB8g7ieLj40V1U6dOFdUdOnRIVAfIO3+kdWa6waSPYbC5rPrNmzdPVDdp0iRRHQB8/PHHQWvOnDkj7iQyFdDy8nIAZ5sRfm7Lli1Ys2YNLBYLPvzwQ2zatAldXV1ITU3FqlWr8MADD5jZDRH9l+mnuINJTU1FdXX1BQ2IiH7CXlwixRhQIsUYUCLFGFAixRhQIsUYUCLFGFAixdTOSbRy5cqgK191dHSIt/fz75wO5uDBg6K6l156SVQnXVUNkHdGSVdgS0pKEu9bqr91MxjpsZiZD0m8IphghTEzddLV5ADZ/WOme4pnUCLFGFAixRhQIsUYUCLFGFAixRhQIsUYUCLFGFAixRhQIsUYUCLF1Lb6NTY2IiYmZtAaaauWmdqJEyeK6qRz+Urb8gBzE4xJSCcX+/HHH0O6X0B+3D09PeJtSh/DUC+7aGZyOsmEZdLxATyDEqnGgBIpxoASKcaAEinGgBIpxoASKcaAEinGgBIpxoASKaa2k+hf//pX0OUHzbBYLKI6aXeJtOvHTBfKyZMnRXXSThTpvs10MEk7f6RdP2YmDZPWmulOCrVgC1oD8gnsAJ5BiVRjQIkUY0CJFGNAiRRjQIkUY0CJFGNAiRRjQIkUY0CJFFPbSXT69OmgNWa6dEK9JJ10TiIzXS3SbbrdblFdfX29qE5yX/eTdsFIH5vu7m7xvqUdVNL7Rzpvkpm5ryTzQJk5Zp5BiRQzFdDy8nJkZmYiLi4OcXFxyM3NxXvvvee/vbu7G0VFRYiPj0dMTAxWrVqF1tbWkA+aaKwwFdCUlBQ88cQTqK2txRdffIHrr78ey5cvx1dffQUA2LBhA9555x288cYbqK6uRktLC1auXDksAycaC0y9Bl22bFnAz48//jjKy8tRU1ODlJQUvPjii6ioqMD1118PANiyZQsuueQS1NTU4KqrrgrdqInGiCG/Bu3r68P27dvR1dWF3Nxc1NbWore3F3l5ef6aOXPmIC0tDXv37h1wO16vFx6PJ+BCRGeZDujBgwcRExMDq9WKO++8Ezt27MDcuXPhcrlgsVjOmZk9KSkJLpdrwO2VlpbCZrP5L6mpqaYPgmi0Mh3Q2bNnY//+/di3bx/uuusuFBYW4uuvvx7yAEpKSuB2u/2X5ubmIW+LaLQx/TmoxWLBzJkzAQDZ2dn4/PPP8eyzz2L16tXo6elBe3t7wFm0tbUVDodjwO1ZrVbx539EY80Ffw7q8/ng9XqRnZ2NyMhIVFZW+m+rq6tDU1MTcnNzL3Q3RGOSqTNoSUkJCgoKkJaWho6ODlRUVKCqqgq7d++GzWbD7bffjuLiYtjtdsTFxeHuu+9Gbm4u38ElGiJTAT127Bh+97vf4ejRo7DZbMjMzMTu3bvx61//GgDwzDPPIDw8HKtWrYLX60V+fj5eeOGFoQ1s3LigrViGYYi35/P5RHXSNqxjx46J6o4cOSKqA+TtcdLJ1BoaGkR1ycnJojpAfp/39vaK6qSPCyBfGlLaEig9FjO/Z5KXa2a2ZyqgL7744qC3R0VFoaysDGVlZWY2S0QDYC8ukWIMKJFiDCiRYgwokWIMKJFiDCiRYgwokWIMKJFiaicNS0lJwYQJEwatOXHihHh73333naiuf3aIYL799ltRXWxsrKgOAGJiYkR1U6ZMEdVJv7rX0tIiqgOA9vZ2UZ10sjQzS0xKJyzr6uoS1UknAzPT7STpBuOkYUSjBANKpBgDSqQYA0qkGANKpBgDSqQYA0qkGANKpBgDSqSY2k6iTz/9FFFRUYPWSLtaAKCpqUlUd+rUKVFdenq6qM5Mp4x0+tGwsDBR3fHjx0V10vmVAMBut4vqzpw5I6oL9hj/nPR4zHSYSZhZ5lIyF5OZJSl5BiVSjAElUowBJVKMASVSjAElUowBJVKMASVSjAElUowBJVJMbSeRZP4ZMwv/Tp06VVQnXZVLWmeGdJvSuXSkq3xlZGSI6gAEnSeqn3QlskmTJon3bbFYRHVutzukddLuMmmtdG4lgGdQItUYUCLFGFAixRhQIsUYUCLFGFAixRhQIsUYUCLFGFAixRhQIsXUtvpFREQEbVUzM5mTtE1MWifdt5kxSklb/aQTdxmGId63dOk86URkbW1t4n3bbDZRnXQisvj4eFGdw+EQ1QHAuHHBI3X69Gnx9kydQcvLy5GZmYm4uDjExcUhNzcX7733nv/2RYsWISwsLOBy5513mtkFEf2MqTNoSkoKnnjiCWRkZMAwDLz88stYvnw5vvzyS8ybNw8AsHbtWjz66KP+/2Nm2kkiCmQqoMuWLQv4+fHHH0d5eTlqamr8AR0/fryppwRENLAhv0nU19eH7du3o6urC7m5uf7rX331VSQkJGD+/PkoKSkJ+vUbr9cLj8cTcCGis0y/SXTw4EHk5uaiu7sbMTEx2LFjB+bOnQsAuOWWW5Ceng6n04kDBw7g/vvvR11dHd58880Bt1daWopHHnlk6EdANIqFGWbewsPZaeubmprgdrvxl7/8BX/+859RXV3tD+nPffTRR1i8eDHq6+sxY8aM827P6/UGfIHV4/EgNTUV9957b9AvZA/HO6RSY/VdXOmyE6H+UjkQ+ndxpXWRkZGiOkD+Lm5RURHcbjfi4uIG3554z/9lsVgwc+ZMAEB2djY+//xzPPvss/jTn/50Tm1OTg4ADBpQq9VqamYEorHkghsVfD7fgFM47N+/HwCQnJx8obshGpNMnUFLSkpQUFCAtLQ0dHR0oKKiAlVVVdi9ezcaGhpQUVGBG264AfHx8Thw4AA2bNiAhQsXIjMzU7yP/qdbknlb+BR3cKPtKa60SUJKetzS+xEw16gg2r9hwu9//3sjPT3dsFgsxuTJk43Fixcb77//vmEYhtHU1GQsXLjQsNvthtVqNWbOnGnce++9htvtNrMLo7m52QDACy+j/tLc3Bw0D6bfJBpuPp8PLS0tiI2N9f+17n/jqLm5OeiL6ovBaDoeHot5hmGgo6MDTqcz6DMNdb244eHhSElJOe9t/S2Go8VoOh4eiznSd6T5bRYixRhQIsUuioBarVZs3Lhx1HxeOpqOh8cyvNS9SUREP7kozqBEYxUDSqQYA0qkGANKpBgDSqTYRRHQsrIyTJ06FVFRUcjJycE//vGPkR7SkDz88MPnTKo2Z86ckR6WyJ49e7Bs2TI4nU6EhYVh586dAbcbhoGHHnoIycnJiI6ORl5eHg4fPjwygw0i2LGsWbPmnMdp6dKlIzJW9QF97bXXUFxcjI0bN+Kf//wnsrKykJ+fL57WUZt58+bh6NGj/sunn3460kMS6erqQlZWFsrKys57+1NPPYXnnnsOmzdvxr59+zBhwgTk5+eH/BsooRDsWABg6dKlAY/Ttm3b/ocj/BlTXzUZAQsWLDCKior8P/f19RlOp9MoLS0dwVENzcaNG42srKyRHsYFA2Ds2LHD/7PP5zMcDofx9NNP+69rb283rFarsW3bthEYodwvj8UwDKOwsNBYvnz5iIznl1SfQXt6elBbW4u8vDz/deHh4cjLy8PevXtHcGRDd/jwYTidTkyfPh233normpqaRnpIF6yxsREulyvgcbLZbMjJybloH6eqqiokJiZi9uzZuOuuu0xNsB1KqgN64sQJ9PX1ISkpKeD6pKQkuFyuERrV0OXk5GDr1q3YtWsXysvL0djYiGuvvRYdHR0jPbQL0v9YjJbHaenSpXjllVdQWVmJJ598EtXV1SgoKBiRCQLUfd1sNCsoKPD/OzMzEzk5OUhPT8frr7+O22+/fQRHRj930003+f996aWXIjMzEzNmzEBVVRUWL178Px2L6jNoQkICIiIi0NraGnB9a2vrqJgce+LEiZg1axbq6+tHeigXpP+xGK2P0/Tp05GQkDAij5PqgFosFmRnZ6OystJ/nc/nQ2VlZcBk2Rerzs5ONDQ0XPSTqk2bNg0OhyPgcfJ4PNi3b9+oeJyOHDmCtra2EXmc1D/FLS4uRmFhIa644gosWLAAmzZtQldXF2677baRHppp99xzD5YtW4b09HS0tLRg48aNiIiIwM033zzSQwuqs7Mz4AzS2NiI/fv3w263Iy0tDevXr8djjz2GjIwMTJs2DQ8++CCcTidWrFgxcoMewGDHYrfb8cgjj2DVqlVwOBxoaGjAfffdh5kzZyI/P/9/P9iRfhtZ4vnnnzfS0tIMi8ViLFiwwKipqRnpIQ3J6tWrjeTkZMNisRhTpkwxVq9ebdTX14/0sEQ+/vjj8058VVhYaBjG2Y9aHnzwQSMpKcmwWq3G4sWLjbq6upEd9AAGO5ZTp04ZS5YsMSZPnmxERkYa6enpxtq1aw2XyzUiY+X3QYkUU/0alGisY0CJFGNAiRRjQIkUY0CJFGNAiRRjQIkUY0CJFGNAiRRjQIkUY0CJFPt/jhiX1h80bVkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_pedestrian = cv2.imread(train_pedestrians[170], cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img_pedestrian, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uIfcqkiWJCQ2",
   "metadata": {
    "id": "uIfcqkiWJCQ2"
   },
   "source": "Image shape visualization"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c0a3c79bca639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:36.112109Z",
     "start_time": "2024-05-14T03:52:36.099110Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "753c0a3c79bca639",
    "outputId": "666583e7-6da9-43cc-aa30-066ca9fff8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 18)\n"
     ]
    }
   ],
   "source": [
    "print(img_pedestrian.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t5slzfjQJVFU",
   "metadata": {
    "id": "t5slzfjQJVFU"
   },
   "source": [
    "Let's calculate the `Histogram of Oriented Gradients (HOG)` for a pedestrian image. Here is what each argument means and how it contributes to the HOG calculation:\n",
    "\n",
    "- **img_pedestrian:** This is the pedestrian image on which the HOG will be calculated. It is the image you previously loaded using `OpenCV` and converted to grayscale.\n",
    "\n",
    "- **orientations:** This parameter specifies the number of orientation bins into which the `gradient angle` will be divided. In this case, it is set to 10, meaning the `gradient angle` will be divided into `10 bins`.\n",
    "\n",
    "- **pixels_per_cell:** This parameter sets the size of the cell in which the gradient histogram will be computed. It is specified as a tuple of two values, where the first value represents the number of pixels in the horizontal direction and the second value represents the number of pixels in the vertical direction. In this case, it is set to `(6, 6)`, meaning 6x6 pixel cells will be used.\n",
    "\n",
    "- **cells_per_block:** This parameter sets the size of the block over which the gradient histograms will be normalized. It is also specified as a tuple of two values, where the first value represents the number of cells in the block in the horizontal direction and the second value represents the number of cells in the block in the vertical direction. In this case, it is set to `(2, 2)`, meaning gradient histograms will be normalized over 2x2 cell blocks.\n",
    "\n",
    "- **transform_sqrt:** This parameter indicates whether to apply a square root transformation to the histograms before normalizing them. In this case, it is set to False, meaning no additional transformation will be applied.\n",
    "\n",
    "- **visualize:** This parameter specifies whether to return an image of the gradient orientations. In this case, it is set to True, meaning an image of the gradient orientations will be computed and returned.\n",
    "\n",
    "- **feature_vector:** This parameter indicates whether to flatten the HOG result into a one-dimensional vector. In this case, it is set to True, meaning the HOG result will be returned as a one-dimensional feature vector.\n",
    "\n",
    "The result of the HOG calculation are two values:\n",
    "\n",
    "- **features:** This is the one-dimensional feature vector resulting from the HOG calculation.\n",
    "- **hog_image:** This is an image that visualizes the gradient orientations. This image can be useful for visualizing how the HOG features are being computed on the original image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f082c1fca8983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:36.128107Z",
     "start_time": "2024-05-14T03:52:36.115108Z"
    },
    "id": "4c2f082c1fca8983"
   },
   "outputs": [],
   "source": [
    "features, hog_image = hog(img_pedestrian,\n",
    "                          orientations=10,\n",
    "                          pixels_per_cell=(6, 6),\n",
    "                          cells_per_block=(2, 2),\n",
    "                          transform_sqrt= False,\n",
    "                          visualize=True,\n",
    "                          feature_vector=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9359d2b116e790f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:36.144105Z",
     "start_time": "2024-05-14T03:52:36.130104Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9359d2b116e790f",
    "outputId": "c670d640-98fb-4c8b-b090-9f3f33af1930"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b4f333db4d5b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:36.384108Z",
     "start_time": "2024-05-14T03:52:36.151106Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "219b4f333db4d5b5",
    "outputId": "e3549771-be6a-4eb4-831b-3d6d89d1ba0b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(hog_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfcd8b2fa17cb09",
   "metadata": {
    "id": "4dfcd8b2fa17cb09"
   },
   "source": [
    "# 游븷 **Extracting HOG Features for the Data**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e_bmRy6kKe0n",
   "metadata": {
    "id": "e_bmRy6kKe0n"
   },
   "source": [
    "Let's start by defining a function that extracts Histogram of Oriented Gradients (HOG) features from a list of images, consisting of the following parameters:\n",
    "\n",
    "- **def extract_hog_features(img_data_list: list) -> list::**\n",
    "  - **def:** Defines a new function.\n",
    "  - **extract_hog_features:** This is the name of the function.\n",
    "  - **(img_data_list: list) -> list:** Specifies that the function takes a list of image data as input and returns a list of HOG features.\n",
    "  - **hog_data = list():** Initializes an empty list called hog_data. This list will be used to store the HOG features of each processed image.\n",
    "\n",
    "- **for img_data in img_data_list::** This loop iterates over each element in the provided image data list.\n",
    "\n",
    "- **img = cv2.imread(img_data, cv2.COLOR_BGR2GRAY):** Loads the image using `OpenCV (cv2.imread())`. The parameter `cv2.COLOR_BGR2GRAY` indicates that the image will be loaded in grayscale. The loaded image is assigned to the variable img.\n",
    "\n",
    "- **img_hog_feature, img_hog_image = hog(img, orientations=10, pixels_per_cell=(6, 6), cells_per_block=(2, 2), transform_sqrt=False, visualize=True, feature_vector=True):** Computes the HOG features of the image using the `hog()` function from the `skimage.feature` module. The specified parameters are similar to those explained earlier. It returns both the HOG features `(img_hog_feature)` and an image of the gradient orientations `(img_hog_image)`.\n",
    "\n",
    "- **hog_data.append(img_hog_feature):** Adds the HOG features of the current image to the hog_data list.\n",
    "\n",
    "- **return hog_data:** Returns the hog_data list, which contains the HOG features of all processed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1237d3f159ef0e60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:52:36.399717Z",
     "start_time": "2024-05-14T03:52:36.385711Z"
    },
    "id": "1237d3f159ef0e60"
   },
   "outputs": [],
   "source": [
    "def extract_hog_features(img_data_list: list) -> list:\n",
    "    hog_data = list()\n",
    "    for img_data in img_data_list:\n",
    "        img = cv2.imread(img_data, cv2.COLOR_BGR2GRAY)\n",
    "        img_hog_feature, img_hog_image = hog(img,\n",
    "                                             orientations=10,\n",
    "                                             pixels_per_cell=(6, 6),\n",
    "                                             cells_per_block=(2, 2),\n",
    "                                             transform_sqrt= False,\n",
    "                                             visualize=True,\n",
    "                                             feature_vector=True)\n",
    "        hog_data.append(img_hog_feature)\n",
    "\n",
    "    return hog_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ivfw0T6XLVK1",
   "metadata": {
    "id": "ivfw0T6XLVK1"
   },
   "source": [
    "Now, let's prepare the training data for the support vector machine (SVM) model that will be used for pedestrian detection. To better understand the process, let's explain it:\n",
    "\n",
    "- **Extraction of HOG features for pedestrians and non-pedestrians:**\n",
    "\n",
    "  - **X_train_pedestrians = np.vstack(extract_hog_features(train_pedestrians)).astype(np.float32):** Extracts the HOG features for the pedestrian images in the training set `(train_pedestrians)`. These features are stacked vertically using `np.vstack()`, which means they are combined into a single array. They are converted to `np.float32` type to ensure calculation precision.\n",
    "  - **y_train_pedestrians = np.ones(len(X_train_pedestrians)):** Creates a label array for the pedestrian images, setting all labels to `1 (indicating they are pedestrians)`.\n",
    "\n",
    "  - **X_train_non_pedestrians = np.vstack(extract_hog_features(train_non_pedestrians)).astype(np.float32):** A similar process is performed for the non-pedestrian images `(train_non_pedestrians)`. The HOG features are extracted, stacked vertically, and converted to `np.float32` type.\n",
    "  - **y_train_non_pedestrians = np.zeros(len(X_train_non_pedestrians)):** Creates a label array for the non-pedestrian images, setting all labels to `0 (indicating they are not pedestrians)`.\n",
    "\n",
    "- **Combining pedestrian and non-pedestrian data:**\n",
    "\n",
    "  - **X_train = np.vstack((X_train_pedestrians, X_train_non_pedestrians)):** Combines the HOG features of pedestrians and non-pedestrians into a single array vertically.\n",
    "  - **y_train = np.hstack((y_train_pedestrians, y_train_non_pedestrians)):** Combines the labels of pedestrians and non-pedestrians into a single array horizontally.\n",
    "\n",
    "- **Randomizing the data:**\n",
    "\n",
    "  - **random_state = np.random.RandomState(seed=42):** Initializes a random number generator with a fixed seed to ensure reproducibility of results.\n",
    "  - **indices = random_state.permutation(len(X_train)):** Generates random indices for the training data.\n",
    "  - **X_train_shuffled = X_train[indices]:** Randomly rearranges the training feature data.\n",
    "  - **y_train_shuffled = y_train[indices]:** Rearranges the training labels according to the shuffled feature data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb721798e626d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:54:47.238716Z",
     "start_time": "2024-05-14T03:52:36.402718Z"
    },
    "id": "21cb721798e626d2"
   },
   "outputs": [],
   "source": [
    "X_train_pedestrians = np.vstack(extract_hog_features(train_pedestrians)).astype(np.float32)\n",
    "y_train_pedestrians = np.ones(len(X_train_pedestrians))\n",
    "\n",
    "X_train_non_pedestrians = np.vstack(extract_hog_features(train_non_pedestrians)).astype(np.float32)\n",
    "y_train_non_pedestrians = np.zeros(len(X_train_non_pedestrians))\n",
    "\n",
    "X_train = np.vstack((X_train_pedestrians, X_train_non_pedestrians))\n",
    "y_train = np.hstack((y_train_pedestrians, y_train_non_pedestrians))\n",
    "\n",
    "# Poner datos de forma aleatoria\n",
    "random_state = np.random.RandomState(seed=42)\n",
    "indices = random_state.permutation(len(X_train))\n",
    "X_train_shuffled = X_train[indices]\n",
    "y_train_shuffled = y_train[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HfeFDiV8MXKI",
   "metadata": {
    "id": "HfeFDiV8MXKI"
   },
   "source": "Now let's remove the variables that contain the labels/features from the training set:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cedb36b0c813ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:54:47.255723Z",
     "start_time": "2024-05-14T03:54:47.240712Z"
    },
    "id": "1cedb36b0c813ce1"
   },
   "outputs": [],
   "source": [
    "del X_train\n",
    "del y_train\n",
    "del train_pedestrians\n",
    "del train_non_pedestrians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V9OHoOEmMvKD",
   "metadata": {
    "id": "V9OHoOEmMvKD"
   },
   "source": "Next, we will prepare the test data, which works very similarly to the structure used for the training data.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855dd0011f0daea5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:56:14.712712Z",
     "start_time": "2024-05-14T03:54:47.259714Z"
    },
    "id": "855dd0011f0daea5"
   },
   "outputs": [],
   "source": [
    "X_test_pedestrians = np.vstack(extract_hog_features(test_pedestrians)).astype(np.float32)\n",
    "y_test_pedestrians = np.ones(len(X_test_pedestrians))\n",
    "\n",
    "X_test_non_pedestrians = np.vstack(extract_hog_features(test_non_pedestrians)).astype(np.float32)\n",
    "y_test_non_pedestrians = np.zeros(len(X_test_non_pedestrians))\n",
    "\n",
    "X_test = np.vstack((X_test_pedestrians, X_test_non_pedestrians))\n",
    "y_test = np.hstack((y_test_pedestrians, y_test_non_pedestrians))\n",
    "\n",
    "# Poner datos de forma aleatoria\n",
    "indices = random_state.permutation(len(X_test))\n",
    "X_test_shuffled = X_test[indices]\n",
    "y_test_shuffled = y_test[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W_3SEh_GM3Lv",
   "metadata": {
    "id": "W_3SEh_GM3Lv"
   },
   "source": "We finish by removing the variables that contain the labels/features from the test set."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27a8c1e8e06aad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T03:56:14.728718Z",
     "start_time": "2024-05-14T03:56:14.714715Z"
    },
    "id": "b27a8c1e8e06aad5"
   },
   "outputs": [],
   "source": [
    "del X_test\n",
    "del y_test\n",
    "del test_pedestrians\n",
    "del test_non_pedestrians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722bf9aa3954fd4b",
   "metadata": {
    "id": "722bf9aa3954fd4b"
   },
   "source": [
    "# 游눩 **SVM Model and Training**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vhNfOijWNMo3",
   "metadata": {
    "id": "vhNfOijWNMo3"
   },
   "source": [
    "Let's create and train a Support Vector Machine (SVM) model using the randomized training data `X_train_shuffled` and `y_train_shuffled`, which includes the following:\n",
    "\n",
    "- **Creating the SVC model:**\n",
    "\n",
    "  - **svc_model = SVC():** Instantiates an object of the SVC class from the `sklearn.svm` module. By default, this constructor creates an SVM model with an RBF (Radial Basis Function) kernel. This model will be used to classify the input data into specific categories `(in this case, pedestrians and non-pedestrians)`.\n",
    "\n",
    "- **Training the model:**\n",
    "\n",
    "  - **svc_model.fit(X_train_shuffled, y_train_shuffled):** Uses the `fit()` method of the `svc_model` object to train the SVM model using the randomized training data `X_train_shuffled` as features and `y_train_shuffled` as labels. During training, the model learns to classify the input data into the specified categories `(1 for pedestrians and 0 for non-pedestrians)` using the Support Vector Machine algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacafb2fb22019e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T04:01:07.737004Z",
     "start_time": "2024-05-14T03:57:49.063050Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "caacafb2fb22019e",
    "outputId": "19c08971-59fd-4cf9-ff00-ee16cd1b4395"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"郊\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"郊쬪";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_shuffled, y_train_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bOebliuNvPA",
   "metadata": {
    "id": "6bOebliuNvPA"
   },
   "source": [
    "Now let's make predictions on the randomized test data `X_test_shuffled`:\n",
    "\n",
    "- **y_pred = svc_model.predict(X_test_shuffled):** Uses the `predict()` method of the `svc_model` to make predictions on the randomized test features `X_test_shuffled`. This method takes the test features as input and returns the predicted labels for those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18336c6998f92e19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T04:04:23.612103Z",
     "start_time": "2024-05-14T04:01:41.671041Z"
    },
    "id": "18336c6998f92e19"
   },
   "outputs": [],
   "source": [
    "y_pred = svc_model.predict(X_test_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9347e",
   "metadata": {
    "id": "0aa9347e",
    "outputId": "d2b10dd5-99a3-40ed-de43-ef7fc5d19185"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc_model.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar el modelo resultante\n",
    "joblib.dump(svc_model, 'svc_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R2crTVv_N9Sb",
   "metadata": {
    "id": "R2crTVv_N9Sb"
   },
   "source": [
    "# 游댍 **Model Metrics Validation**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DfVVmB6BOkeO",
   "metadata": {
    "id": "DfVVmB6BOkeO"
   },
   "source": [
    "Let's generate a confusion matrix and visualize it as a heatmap using the Seaborn and Matplotlib libraries, as follows:\n",
    "\n",
    "- **cm = confusion_matrix(y_test_shuffled, y_pred, labels=[0, 1]):** Calculates the confusion matrix using the `confusion_matrix()` function from `Scikit-learn`. This matrix compares the true labels `y_test_shuffled` with the predicted labels `y_pred`. The confusion matrix is a tool that shows **the number of correct and incorrect predictions** for each class `(in this case, 0 for non-pedestrians and 1 for pedestrians)`. The `labels=[0, 1]` parameter is used to specify the order of the labels in the confusion matrix.\n",
    "\n",
    "- **sns.heatmap(cm, annot=True, fmt='g', cmap='Purples', cbar=False):** Uses the `heatmap()` function from Seaborn to visualize the confusion matrix `cm` as a heatmap. The parameters used are:\n",
    "\n",
    "  - **cm:** The confusion matrix to visualize.\n",
    "  - **annot=True:** Adds annotations to the cells of the heatmap to show the values of the confusion matrix.\n",
    "  - **fmt='g':** Sets the format of the annotations to general format.\n",
    "  - **cmap='Purples':** Uses the 'Purples' color scheme for the heatmap, which is a color palette ranging from light to dark purple tones.\n",
    "  - **cbar=False:** Disables the side color bar in the heatmap.\n",
    "  - **plt.show():** Displays the generated heatmap using the `show()` function from Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7f612d07e7d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T04:04:39.796788Z",
     "start_time": "2024-05-14T04:04:39.644756Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "b7e7f612d07e7d14",
    "outputId": "72400ba0-b88e-4d41-9153-5b6cb0b00ed9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAGdCAYAAAC7JrHlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYsklEQVR4nO3ceZiXdb3/8dewDYoCosiMoOGaWz8hTBQzUCjUVKxcyuWo2aIVLqQm7pqFpqWRWoqZespSQ61zzFxQf2SSIIhL4oKQC6vDIqvDMnP+8DSdCdQwPjOoj8d1zXXxve/P9573fV0zzHPu7/2divr6+voAABTSorkHAAA+2MQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKJaNfcAf9ev4rzmHgEoZNTyC5p7BKCQlq3e/bqFKxsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAU1aq5B+D9ab0N2uT47/bPJz+3QzbatF1efGJGfnLyH/L849OTJGf+4nPZ99iejZ4z9o8v5oz9/rPh8W+mnpqq7hs1WnPdmffnlkv/1PC436E75aizPpVu222c+a8vyZ1XPZZbL/9zwTMD3smIESNyxZU/ytFHHZ2hQ89qtK++vj5fP+HreeSRP2X48J9kQP8BDfu+9/3v5YknJuTFF1/MVlttnTvvuLOpR6cZiQ3ek9OvH5Qtd+6S7x89MnOmL8ynj9olP3zg2By7409SM31hkuSxe17Mpcf94z+UZbUrVjnOz88dlbtHjG94vGRhbcO/d9t325zzq0MyfPDdGXffS/nIDp1z2oiDsmzp8tx59diCZwesztNPP53bbr81H93uo6vdf/PNN6Wi4u2f//nPfT5PPf1Unn/+hUITsq7yMgprrE3bVun7hR1z7Rn35ak/vZxpL83NjRc+lGmT52bQibs1rFteuyJzZy1q+Fg0/81VjrV04bJGa95csrxh32eO3iWP3DUpv7/28cyYOi9/+cML+dWwP+VL39mrSc4T+IfFixfnjO+cngsvvCjtO7RfZf+kSZNy40035uLvfm+1zz/7rLNzxBFHplu3zUuPyjpIbLDGWrZqkZatWmbZm42vVCxbujwf++QWDY979OueO2edkZufOymnXnNA2ndab5VjHXHmJ/O7mjMzYsKJOfy0PdOy5T++JFtXrv5zbLp5h1R9pOPaPSngHV188XfT91N902ePPqvsW7p0aU4/4/Scc8656dy5czNMx7pujV9GqampyQ033JAxY8Zk5syZSZKqqqr06dMnxx57rC+0D4Gli5blmUdfyX+c2zcvT3o982YtSv8vfSw77rF5pk2em+St+zNG3/FsZkydl65bd8pXvj8gl95zdL65x4jU1dUnSUYOfywvTpieBXOXZuc+m+erwz6djas3zDXf/mOSZNy9k/PNK/bLx2+cmCcempqu23TKYd/eM0nSqXrDzHx5frOcP3zY/OEPd+fZSc/mtltvX+3+Sy69JD179kj/ffo38WS8X6xRbIwbNy4DBw7M+uuvnwEDBmS77bZLksyaNSvDhw/PJZdcknvvvTe77rrrOx6ntrY2tbW1jbbVZUVauIXkfeP7R4/MGTd8LiOnn56VK1bmhQkz8uCvn852vTZLkjx46zMNa6c+MzsvPTUrv55yanr02zITHpySJLn9ikcb1kx5elaWL1uZb197UEYMvT/Ll63Mf48Yn8227pRh/31kWrVukcULajPyx3/JcRfuk/r/DRagrBkzZmTYJcNy/Yifp7KycpX9Dz74YB577C8Z+ds7mmE63i/W6Kf74MGDc+ihh+ZnP/tZKv7pLqD6+vqccMIJGTx4cMaMGfOOxxk2bFguvPDCRts+kk+le/quyTg0o+lT5uWUfjek7fqts377ysyduSjn/ebQTJ8yb7XrZ0ydl/mvL07XbTo1xMY/m/TYa2nVumWqunfMqy/MSfLWu1OuP+uBdKraIPNfX5KP99/qfz//3DInBjTy12f/mjlz5uSQQ7/QsG3lypV5/PHHc8uvb8nhh38xr776anbfo3ej551yysnp1atXbrrx5qYemXXQGsXGk08+mRtvvHGV0EiSioqKnHrqqenZs+dqntnY0KFDM2TIkEbbDuhwyZqMwjrizSXL8+aS5dmgY9vsNnCb/OyM+1a7rnPX9mm/8XqZM2Ph2x5rmx7VWbmyLvNmL260va6uvuEdLv2/9LE88+greaNmydo7CeBt7bH7HvndXb9rtO3ss8/Ollttma8c/5V07LhRDj/ssEb7Bx08KN/5zpnZu9/eTTkq67A1io2qqqqMHTs222+//Wr3jx07Nl26dHnX41RWVq5yOc5LKO8vn/jMNqmoSF55viZdt9k4J172mbzyXE3u+cUTWa9dmxxzfr+MHvls5s5clM227pSv/+AzmTZ5bsbdOzlJsuPum2fH3t3yxENTsmThsuy0x+b55hX75v5fPtnwrpUOG6+fvofsmIkP/y1t2rbKvsf1TL9Dd8rJfW9ozlOHD5V27dpl2223a7RtvfXXS8cOHRu2r+5everq6nTr1q3h8csvv5wlS5akpqYmtbVvZtKkSUmSrbfeOm3atCl4BqwL1ugn/GmnnZavfe1rGT9+fPr3798QFrNmzcqoUaMyYsSIXH755UUGZd3SrkNlvjrs0+ncrX0Wzl2a0SOfzfVnP5CVK+qyslVdtvp/VRl4TI9s0LFt5kxfmHH3vZQbzh2V5ctWJnnrbbH7fHHnHHtBv7SubJUZU+fl9ivG5PYfPdro8ww8pmdOvHxgUlGRZ8e8mlP6/SLPjZvWHKcM/BvOO//cjBs3ruHxFw75fJLk/vseSNeuXZtrLJpIRX19/RrdaXfrrbfmiiuuyPjx47Ny5Vs/OFq2bJlevXplyJAhOeyfLqf9q/pVnPeenges+0Ytv6C5RwAKadnq3f+KxhrHxt8tX748NTU1SZJNNtkkrVu3fi+HaSA24INLbMAH178SG+/5RonWrVunurr6vT4dAPiQ8BdEAYCixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKKqivr6+vrmHSJIF85c29whAISfs/fPmHgEo5JYnvvWua1zZAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAU1aq5B+D9acIT4/Ofv7wpzz03KTU1r+eyH/wo/frus9q1wy65OHfc+ducesppOeJLRzXa98gjo3P9Dddl8uQX06ZNm3y8Z69cftmVqxxj/hvzc+SRh2X267Pz4AOjs+GG7UucFnzoVbSoyCEn7JY99/9oOm68fua9vjij/2tS7hzxeMOaT+yzVfofsnO23GHTbNixbYYe/pu8/EJNo+Mcf3a/7Nx782zUuV3eXLo8Lzw5I7/58aOZ/rf5jdZ96sDts/9RPVL1kY5ZunhZHrt/cm68ZHRTnCpNSGzwnixdujTbbbtdDjrw4JzxnSFvu+6hhx/M0888lc6dO6+y78EHH8j3hl2Ub5w4OLvuultWrliRl6ZMXu1xLr74gmyzzbaZ/frstXYOwKoOOvbjGXDIzvnpeQ/ktZfmZqudNs3XL+ifJYuW5d5fP5UkqVyvdZ6fOCN/uX9yvnbe6n/JmDrp9fz5nhdSM2NhNujQNl84Ybecec2gnHzAzamvq0+S7H9Uj+x/dI/ccsWjmfzMzFSu1zqdN9uwyc6VpiM2eE/27PPJ7Nnnk++4ZvbsWbn88ksyfPg1OXXI4Eb7VqxYkR/+6Ac5afCpGXTQ5xq2b7XV1qsc57cjb8vCRQvzleO/nkfH/HntnACwWtvuUp3H///UTHzk5SRJzYyF6bPvdtl6py4Nax65+/kkySbVbx8GD97x14Z/18xYmNuu/ksuve1L6bzZhpn92oK027Ayh36jdy4/5e78dexrDWtffXHO2j4l1gHu2aCIurq6nH/BOTnqqGOy9VbbrLL/+ecnZfbrs1NRUZEjjz48++4/ICed8s1MfqnxlY0pU17K9T+/Lheef3FaVFQ01fjwofXikzOy827dUrVFxyTJFtttnI/2qM6Tf375PR+zsm2r9D1oh8x+7Y3MmbkoSbLz7punokVFOm3aLpeNPCI/+eOxOenSgenUZYO1cRqsY1zZoIibbv5FWrZsmS8efsRq90+bNi1JMuL6a3Pqyd9OdfVm+dUtN+eEE7+Skbf/Lh06dMiyZctyzrlDc9LgU1NVVZ1p015b7bGAtef3vxif9TZok8vvPDJ1K+vSomWL3Hb1X/Lne15Y42MNOHTnHHFKn7Rdv02mT52X75/4u6xcUZck2bRb+7RoUZFBX941N1/2pyxZVJvDvrl7zvrpoHznsF83rOODYa1f2Xj11Vfz5S9/+R3X1NbWZsGCBY0+amtr1/YoNJNJk57Nb269Jeefd1Eq3uZqRF39W/+RHHfs8dlnnwHZYYcdc965b60fNer+JMnV1wxP9+5bZv/9Pttks8OH3e6f2TZ77rddrj7rvpx9xG352XkP5LNH98xeB26/xsf68z0v5Kwv3ZqLjr8jM16Zn5Mv3Tet27RMkrSoqEir1i1z0w9G56kxr2Ty07Pyk6H3pmqLDtnpE93W9mnRzNZ6bMydOzc33XTTO64ZNmxYOnTo0OjjR1dctrZHoZk8MXFC5s2bmwMH7Zfd+/TK7n16ZcaMGfnx8B/loIP3S5JssvFbN4xuteU/7tFo06ZNunbtmpmzZiRJxj0+NqMevL/hGN/41teTJJ8euHeuve6aJj4r+HA44pQ++f0vJmTMvS/m1clz8sjdz+eeX03MoON6rfGxli5alpmvvJHnJkzPlafdk+otN8qu+2yVJJlfsyRJMm3K3Ib1C+e9mYXz38zGVV5K+aBZ45dRfv/737/j/ilTprzrMYYOHZohQxq/g6F2qUtmHxT7739Adttt90bbTjr5xOy33wE58IBBSZLtt98hbdq0ycuv/C09evRMkqxYsTwzpk9PVVV1kuQHl/wwb/6fK17PPvtMvnvxBbnu2hvSrevmTXQ28OHSpm3r1NfXN9pWV1efihb/3j1TFRVJRZLWrd+6svH8xLd+qajuvlHmzl6cJGnXvjIbdmybmhkL/63PxbpnjWPj4IMPTkVFxSpfjP/X2106/7vKyspUVlY22ragbumajkIzWrJkSV597ZWGx9OnT8vzLzyXDu07pKqqOh07dGy0vlWrVtm408bp/pHuSZINNtggn//cIbnuup+my6ZdUlW9WX75y7euiA3o/5kkSbdujYPijfnzkiRbdt/S39mAQiaMnppBx++amhkL89pLc9N9+87Z/6geefiuZxvWtGtfmU2qNsxGm7ZLklR375gkmT9nSd6YsySbdm2f3Qdum6fHvJIF85amU5cNctBxvbKsdmXDu1xmvjI/jz80Jf9x+l65/uKHsnTRsnxx8B6Z/rd5efbxaU1+3pS1xrFRXV2da665JoMGDVrt/okTJ6ZXrzW/3Mb7y6RJf80J3/hqw+MrrvxhkuSznz0wF5z33X/pGCefdGpatmyV8y84J7W1tdlp551zzTXXpX17IQHN5aZLR+fQb/TOcWf1TYeN3vqjXqN++0zuuG5cw5pefbfMCRcNaHh80qX7JklG/mxsRl47NsuWrcz2Pauz3xG7pF37yrwxZ0memzA9Fxz72yyY949fLH967v056rS9csbwA1JXl0waPy2XfPO/3Bz6AVRR/06XKFbjoIMOSo8ePXLRRRetdv+TTz6Znj17pq5uzb5YFsx3ZQM+qE7Y++fNPQJQyC1PfOtd16zxlY3TTz89ixcvftv922yzTR566KE1PSwA8AG1xrGx1157veP+du3apW/fvu95IADgg8VfEAUAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKCoivr6+vrmHoIPl9ra2gwbNixDhw5NZWVlc48DrEW+v1kdsUGTW7BgQTp06JA33ngj7du3b+5xgLXI9zer42UUAKAosQEAFCU2AICixAZNrrKyMueff76bx+ADyPc3q+MGUQCgKFc2AICixAYAUJTYAACKEhsAQFFigyZ19dVXp3v37mnbtm169+6dsWPHNvdIwFowevToHHjggdlss81SUVGRu+66q7lHYh0iNmgyt956a4YMGZLzzz8/EyZMyC677JKBAwdm9uzZzT0a8G9avHhxdtlll1x99dXNPQrrIG99pcn07t07n/jEJ3LVVVclSerq6rL55ptn8ODBOfPMM5t5OmBtqaioyJ133pmDDz64uUdhHeHKBk1i2bJlGT9+fAYMGNCwrUWLFhkwYEDGjBnTjJMBUJrYoEnU1NRk5cqV6dKlS6PtXbp0ycyZM5tpKgCagtgAAIoSGzSJTTbZJC1btsysWbMabZ81a1aqqqqaaSoAmoLYoEm0adMmvXr1yqhRoxq21dXVZdSoUdljjz2acTIASmvV3APw4TFkyJAcc8wx2XXXXbPbbrvlyiuvzOLFi3Pcccc192jAv2nRokWZPHlyw+OpU6dm4sSJ6dSpU7bYYotmnIx1gbe+0qSuuuqqXHbZZZk5c2Z69OiR4cOHp3fv3s09FvBvevjhh7P33nuvsv2YY47JjTfe2PQDsU4RGwBAUe7ZAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABF/Q87PM45acm1OgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_shuffled, y_pred, labels=[0, 1])\n",
    "sns.heatmap(cm,  annot=True, fmt='g', cmap='Purples', cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LvmZ4hMPPkTA",
   "metadata": {
    "id": "LvmZ4hMPPkTA"
   },
   "source": [
    "- **True Negatives (TN): 9559**\n",
    "\n",
    "  These are cases where the model correctly predicted that the samples did not belong to the pedestrian class (negative class).\n",
    "\n",
    "- **False Positives (FP): 441**\n",
    "\n",
    "  These are cases where the model incorrectly predicted that the samples belonged to the pedestrian class when they actually did not. That is, the model gave a positive result when the truth was negative.\n",
    "\n",
    "- **False Negatives (FN): 1464**\n",
    "\n",
    "  These are cases where the model incorrectly predicted that the samples did not belong to the pedestrian class when they actually did. That is, the model gave a negative result when the truth was positive.\n",
    "\n",
    "- **True Positives (TP): 8136**\n",
    "\n",
    "  These are cases where the model correctly predicted that the samples belonged to the pedestrian class (positive class).\n",
    "\n",
    "To interpret these results:\n",
    "\n",
    "- The model correctly classified `9559` samples as `non-pedestrians`.\n",
    "- The model incorrectly classified `441` samples as `pedestrians` when they actually were `not`.\n",
    "- The model incorrectly classified `1464` samples as `non-pedestrians` when they actually were `pedestrians`.\n",
    "- The model correctly classified `8136` samples as `pedestrians`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343763430b3644e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T04:04:43.402335Z",
     "start_time": "2024-05-14T04:04:43.381332Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b343763430b3644e",
    "outputId": "6faf37ee-fcc2-4607-a9df-72e92695640a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9559  441]\n",
      " [1464 8136]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f3d7f8c833a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T04:04:46.366716Z",
     "start_time": "2024-05-14T04:04:46.313683Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "170f3d7f8c833a3d",
    "outputId": "bd51510a-3974-4d4e-c187-dc24a7b30f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.96      0.91     10000\n",
      "         1.0       0.95      0.85      0.90      9600\n",
      "\n",
      "    accuracy                           0.90     19600\n",
      "   macro avg       0.91      0.90      0.90     19600\n",
      "weighted avg       0.91      0.90      0.90     19600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_shuffled, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qFIL3e3BQS0i",
   "metadata": {
    "id": "qFIL3e3BQS0i"
   },
   "source": [
    "These metrics provide a detailed assessment of the model's performance in terms of precision, recall, F1-score, and weighted average.\n",
    "\n",
    "- **Precision:** It is the ratio of correctly classified positive cases among all cases classified as positive. For class `0 (non-pedestrians)`, the precision is `0.87`, which means that `87%` of the samples classified as **non-pedestrians are indeed non-pedestrians**. For `class 1 (pedestrians)`, the precision is `0.95`, meaning that `95%` of the samples classified as **pedestrians are indeed pedestrians**.\n",
    "\n",
    "- **Recall:** It is the ratio of correctly classified positive cases among all cases that are actually positive. For class `0`, the recall is `0.96`, meaning that `96%` of the non-pedestrian samples were correctly identified as non-pedestrians. For class `1`, the recall is `0.85`, indicating that `85%` of the pedestrian samples were correctly identified as pedestrians.\n",
    "\n",
    "- **F1-score:** It is the harmonic mean of precision and recall. It represents the weighted accuracy and recall of the model in a single metric. For class 0, the F1-score is 0.91, and for class 1, it is 0.90.\n",
    "\n",
    "- **Accuracy:** It is the ratio of samples correctly classified among all samples. In this case, the accuracy is `0.90`, which means that `90%` of all samples were correctly classified by the model.\n",
    "\n",
    "- **Support:** It is the actual number of occurrences of each class in the test dataset. For class `0 (non-pedestrians)`, the support is 10000, indicating there are 10000 samples in the test dataset that belong to the non-pedestrian class. For class `1 (pedestrians)`, the support is 9600, indicating there are 9600 samples in the test dataset that belong to the pedestrian class.\n",
    "\n",
    "- **Macro avg:** It is the simple average of the metrics for all classes. In this case, it is the average of precision, recall, and F1-score for both classes.\n",
    "\n",
    "- **Weighted avg:** It is the weighted average of the metrics for all classes, where the weight is the support of each class. In this case, it is the weighted average of precision, recall, and F1-score for both classes, using the support of each class as weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468497095eebb94",
   "metadata": {
    "id": "468497095eebb94"
   },
   "source": [
    "# 游늳 **Grid Search**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67ab94",
   "metadata": {
    "id": "5a67ab94"
   },
   "source": [
    "Next, this block of code defines a dictionary called `param_grid` that contains a grid of `hyperparameters` to be explored during the `hyperparameter` search through `cross-validation` in the process of fitting the Support Vector Machine (SVM) model.\n",
    "\n",
    "- **'C':** This parameter controls the penalty for classification errors. A smaller value of C implies stronger regularization, leading to a smoother decision boundary. The specified values are `[1, 10, 100, 1000]`, indicating that the hyperparameter search will test these values for the C parameter.\n",
    "\n",
    "- **'gamma':** This parameter controls the width of the Gaussian kernel. A smaller value of gamma means that the radius of influence of the training examples is larger, leading to a smoother and less complex decision boundary. The specified values are `[0.0001, 0.001, 0.01, 0.1, 1]`, indicating that the hyperparameter search will test these values for the gamma parameter.\n",
    "\n",
    "- **'kernel':** This parameter specifies the type of kernel to use in the SVM model. In this case, the radial basis function (RBF) kernel is used, which is one of the most commonly used kernels in SVM. The specified value is `['rbf']`, indicating that only the radial kernel will be tested during the hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24c3286727cd56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T04:05:19.412764Z",
     "start_time": "2024-05-14T04:05:19.403761Z"
    },
    "id": "4d24c3286727cd56"
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e811be",
   "metadata": {
    "id": "91e811be"
   },
   "source": [
    "Now, let's perform an exhaustive hyperparameter search using cross-validation to find the best combination of hyperparameters for the Support Vector Machine (SVC) model.\n",
    "\n",
    "**GridSearchCV(SVC(), param_grid, refit=True, verbose=4):**\n",
    "\n",
    "- **SVC():** This is the estimator on which the hyperparameter search is performed. In this case, `SVC()` is used for a Support Vector Machine (SVM) model.\n",
    "- **param_grid:** This is the dictionary that contains the grid of hyperparameters to be explored. It is defined earlier and contains combinations of values for the hyperparameters C, gamma, and kernel.\n",
    "- **refit=True:** This parameter indicates that the best estimator found with the best hyperparameters will be fitted to the entire training set once the search is complete.\n",
    "- **verbose=4:** This parameter controls the verbosity level of the output during the fitting process. A value of 4 indicates that a message will be printed for each hyperparameter combination during the search.\n",
    "\n",
    "**grid_search.fit(X_train_shuffled, y_train_shuffled):**\n",
    "\n",
    "This method starts the hyperparameter search process and fits the model to the randomized training data `(X_train_shuffled and y_train_shuffled)` using cross-validation.\n",
    "\n",
    "Regarding execution time, it is difficult to give a precise estimate without knowing the size of the data and the complexity of the model. However, exhaustive hyperparameter search can be computationally expensive, especially with a large number of hyperparameter combinations and a large dataset. The execution time will also depend on your hardware's processing capability. In this case, since the exhaustive search involves testing multiple hyperparameter combinations and fitting the model for each of them, the execution time may be long.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11364773617ea3a8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-14T04:06:04.265779Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "id": "11364773617ea3a8",
    "jupyter": {
     "is_executing": true
    },
    "outputId": "ba78733f-3afd-4a1e-aa44-abf361f6f9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.554 total time= 3.4min\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.550 total time= 3.5min\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.554 total time= 3.5min\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.550 total time= 3.5min\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.548 total time= 3.4min\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.864 total time= 2.6min\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.855 total time= 2.6min\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.848 total time= 2.6min\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.856 total time= 2.6min\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.853 total time= 2.5min\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.896 total time= 1.6min\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.884 total time= 1.6min\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.880 total time= 1.6min\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.887 total time= 1.6min\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.884 total time= 1.6min\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.946 total time= 1.1min\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.942 total time= 1.1min\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.940 total time= 1.1min\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.942 total time= 1.2min\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.941 total time= 1.1min\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.962 total time= 7.3min\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.957 total time= 7.1min\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.959 total time= 7.1min\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.960 total time= 7.0min\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.956 total time= 7.1min\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.863 total time= 2.6min\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.855 total time= 2.6min\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.847 total time= 2.7min\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.856 total time= 2.7min\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.852 total time= 2.7min\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.890 total time= 1.8min\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.878 total time= 1.7min\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.875 total time= 1.8min\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.883 total time= 1.7min\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.876 total time= 1.7min\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.916 total time= 1.3min\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.904 total time= 1.3min\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.906 total time= 1.3min\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.908 total time= 1.3min\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.903 total time= 1.3min\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.967 total time= 2.5min\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.964 total time= 2.4min\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.965 total time= 2.5min\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.968 total time= 2.4min\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.966 total time= 2.5min\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.964 total time= 7.1min\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.960 total time= 7.0min\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.962 total time= 7.0min\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.962 total time= 6.9min\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.959 total time= 6.9min\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.890 total time= 1.6min\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.878 total time= 1.6min\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.874 total time= 1.5min\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.882 total time= 1.6min\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.875 total time= 1.6min\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.899 total time= 1.2min\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.885 total time= 1.2min\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.884 total time= 1.2min\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.890 total time= 1.2min\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.885 total time= 1.2min\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.949 total time= 1.6min\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.948 total time= 1.5min\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.946 total time= 1.5min\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.948 total time= 1.5min\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.945 total time= 1.5min\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.970 total time= 2.7min\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.966 total time= 2.6min\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.965 total time= 2.6min\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.969 total time= 2.7min\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.967 total time= 2.7min\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.964 total time= 6.9min\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.960 total time= 6.8min\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.962 total time= 6.9min\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.962 total time= 6.8min\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.959 total time= 6.9min\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.897 total time= 1.2min\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.880 total time= 1.2min\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.882 total time= 1.2min\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.888 total time= 1.2min\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.882 total time= 1.2min\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.912 total time= 1.9min\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.904 total time= 1.8min\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.906 total time= 1.9min\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.909 total time= 1.8min\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.901 total time= 1.8min\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.961 total time= 4.3min\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.961 total time= 4.2min\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.960 total time= 4.3min\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.963 total time= 4.3min\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.962 total time= 4.3min\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.970 total time= 2.7min\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.966 total time= 2.6min\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.965 total time= 2.6min\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.969 total time= 2.7min\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.967 total time= 2.7min\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.964 total time= 6.9min\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.960 total time= 6.8min\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.962 total time= 6.9min\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.962 total time= 6.8min\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.959 total time= 6.9min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"郊\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"郊쬪";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=4)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10, 100, 1000],\n",
       "                         'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=4)\n",
    "grid_search.fit(X_train_shuffled, y_train_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdb801e",
   "metadata": {
    "id": "3cdb801e"
   },
   "source": [
    "After completing the exhaustive hyperparameter search using cross-validation, the `best_params_` attribute of `grid_search` contains a dictionary that specifies the best hyperparameters found during the search process.\n",
    "\n",
    "**grid_search.best_params_:** This attribute returns a dictionary containing the best values for the hyperparameters found during the exhaustive search. Each key in the dictionary corresponds to a hyperparameter, and its value is the best option found for that hyperparameter.\n",
    "\n",
    "For our specific case, the best hyperparameters found are:\n",
    "\n",
    "- **C: 100**\n",
    "- **gamma: 0.1**\n",
    "- **kernel: 'rbf'**\n",
    "\n",
    "This indicates that, according to the hyperparameter search results, the Support Vector Machine (SVM) model achieves the best performance when trained with a regularization parameter C equal to 100, a kernel width parameter gamma equal to 0.1, and using a radial basis function (RBF) kernel. These are the optimal values found that maximize the model's performance on the training dataset during the hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22197cdf4aefffe8",
   "metadata": {
    "id": "22197cdf4aefffe8",
    "outputId": "95c8c50f-3dc1-49d8-fb7f-c81d11763e37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c0d2e2d15c1ed",
   "metadata": {
    "id": "500c0d2e2d15c1ed",
    "outputId": "19d181d2-a563-4228-f2a2-9b6153e2dabc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"郊\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"郊쬪";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, gamma=0.1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef715624",
   "metadata": {
    "id": "ef715624"
   },
   "source": "Let's use the SVM model with the best hyperparameters found during the exhaustive hyperparameter search `(grid_search)` to make predictions on the randomized test dataset `(X_test_shuffled)`.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f49184070389b",
   "metadata": {
    "id": "da4f49184070389b"
   },
   "outputs": [],
   "source": [
    "grid_predictions = grid_search.predict(X_test_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91151aea",
   "metadata": {
    "id": "91151aea"
   },
   "source": "Generated confusion matrix"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65fa8cbfc967257",
   "metadata": {
    "id": "c65fa8cbfc967257",
    "outputId": "87430c4d-d591-483c-f602-ba1e32995f35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAGdCAYAAAC7JrHlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaKklEQVR4nO3ceZzVdaH/8ffMIMO+I4iAuIRLKiIouKA3xUy9KtlPs5up5ZpKN0lNzF0LC01DMW0xLS3t/roulUuJC5ULXhRUXBEXXBgEZZdtZu4f5lwnuHoxPzOoz+fjMX+cz/dzzvl8Hg9meJ3v+Z5TUV9fXx8AgEIqm3sBAMDHm9gAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUFSL5l7AO1bMmdHcSwAKad1rWHMvAShk5fJX3neOMxsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTb4QBYvXpILLrkiexxwWAZ9Zv98+ZhReezJpxuOf+f8i7LlTns1+jlm1OmNHuOFl17OyG+fk533/mKG7HFAvvL1b2XS5KmN5rw2a3a+ftKZGbzbiOyyz8G58LKfZeXK2ibZI7CqU04+PiuXv5KLLjwnSdK5c6dccvF5mfb4xCycPz0zpk/KxT88Nx06tG90vz59euWWm36ZBfOm59WXp+b7Y05PVVVVc2yBZtCiuRfAR9OZF/wo02e8kDFnnpR1u3XN7++4K0f9+2m5+bor06N7tyTJzkMH5/zTTmy4zzrrrNPoMY4/5ez07d0rPx93QVpVt8yvfntTjj/lrNz226vSrWuX1NbW5riTz0rXLp1z7RUX5fW5b+S08y9MixYt8s1jD2/K7QJJBg8akKOOPCRTH32iYaxXrx7p1atHvv3t8/LEk89kg769M378BenVq2e+ePDRSZLKysrccvMvUzPr9Qzbdf+s13Pd/OKqH2XFypU5/YwLmms7NCFnNlhjS5cty533/jWjjj8ig7fZKn1798rxRxySvr175YYb/9gwr+U666Rb1y4NPx3f9UrnzXnz8+LMV3LkIQdl0002zAZ91s+Jx341by1dlmdnvJgkuW/Sw3nuhZdywVknZ7P+G2fYDtvlhCMPzfX/+fusWLGiyfcNn2Rt27bJL395WY79+imZ9+a8hvFp057OQV88On/4458zY8aLufuev+WMM7+ff91neMOZi8/usWu22Lx/Dj18ZKZOnZbb77g7Z509Nl8/9rBVXoTw8SQ2WGO1K2tTW1uX6paN/0hUV7fMw49Oa7j90COPZpd9Ds6/Hnxkzh17aebNX9BwrFPHDtmwb+/ccvuELHlraVaurM1vb741XTp3yhabbpIkmfr4k/nURv3SrUvnhvvtNGRQFi1ekunPv1h4l8C7XTrue7nt1gmZcNdf3nduxw7ts2DBotTWvv2W59Chg/LY409l9uw5DXP+9Od70rFjh3z60/2LrZm1xxq/jTJnzpxcddVVuf/++zNr1qwkSc+ePbPjjjvm8MMPT/fu3T/0RbJ2adu2TQZsuXmuuPo32WiDvunapVNuvfPeTH38qfRdf70kyU5DB2X4rjtl/V49MvOV1/KjK6/Osd86I9dd+cNUVVWloqIiP/3R9/KNU8/LkD0OSGVlRbp06pQrf3hewxmQOW+8ma5dOjV67nduz5n7ZlNuGT7RDjpovwwcuGWG7rDP+87t2rVzvnPaN/Ozn1/XMNajR/fMrnm90byav9/u2WPdJNPCx9saxcZDDz2UPffcM23atMnw4cPTv//bRVpTU5Nx48blggsuyB133JHBgwe/5+MsW7Ysy5YtazRWuWxZqqur13D5NJcxZ5yUM8dcnN1GHJKqqsps3n+T7DV81zzx9PQkyd7D/6Vhbv+NN0z/jTfMXgd9LQ898miGDh6Y+vr6fPeiy9O1c8dcc/nYtKquzu9+f3tOOOXsXP+zcenerUsz7Qx4t969e+Xii87N5/b+0ip/t/9R+/bt8vubf5knn3wm55x7UROtkI+CNYqNkSNH5sADD8wVV1yRioqKRsfq6+tz7LHHZuTIkbn//vvf83HGjBmTc845p9HY6Sd/I2ee8u9rshyaUd/evXL1+LFZ8tbSLF68JN27dcm3zhiT3r16rnZ+n/XXS+dOHfLSy69l6OCBeXDylNx736Tcd/tv065t2yTJFpuekPsfeiQ333ZnjvzKQenWpXMee+KZRo8z9415SZJuXTv/41MABWy77Vbp0aN7Hnrw9oaxFi1aZNiwoTn+uMPTpt2GqaurS7t2bXPrH67LwoWL84UDj8zKlSsb5tfUvJ7tthvY6HF79Hj7LPismtlNsxGa1RpdszF16tSceOKJq4RGklRUVOTEE0/MlClT3vdxRo8enfnz5zf6+fa/H7smS2Et0aZ1q3Tv1iXzFyzMfZMmZ7dhQ1c7b9bs1zNv/sJ07/r2GYulS99+hVRZ0fifYGVFRerq6pIkA7bcPM/OeCFz33Ux2v0PPZx2bdtk4359C+wG+Ed33fXXDBi4WwZt99mGn4f+a0p+/ZsbM2i7z6auri7t27fL7bf+JsuXL8+IAw5f5QzIAw9MzlZbbpbu3bs2jA3ffZfMn78gTzzxbFNviWawRmc2evbsmUmTJmWzzTZb7fFJkyalR48e7/s41dXVq7xlsmL5nP9lNmujvz04OfX19enXt3deevnVXDT+59mwb++M2OezWbLkrVx+1XXZ4192SreuXTLzlVfzw8uvSt/evbLTkG2TvB0SHdq3y2nnX5Rjv/pvaVXdMv//ltvz8ms12WXH7ZMkO26/bTbu1zejzx2bUccdkblvvJlLf/LLHHzAvmnZsmVzbh8+MRYtWpxp055uNLZk8ZLMnftmpk17uiE0WrdplUMPH5kOHdo3fMfG66/PTV1dXf7053vzxJPP5JpfjMupp303PXt0z7nnnJIfX3FNli9f3hzboomtUWycdNJJOfroozN58uTsvvvuDWFRU1OTCRMm5Kc//WkuvPDCIgtl7bJw0eJccsUvUvP6nHTs0D577LpzvnHMYVmnRYvU1tbmmeeezy233ZkFixZn3W5dsuP22+aEow5tiITOnTrmiovOy7ifXJMjvnFqVq5cmU023CCXXnBmNvvURkmSqqqqjB97ds4be1kOOWZUWreuzn57Dc8JR36lObcOvMu2A7fKkL+/iHjmqfsaHdv4U0Py4osvp66uLvuPOCzjLx2Tv068JYsXL8mvfvUfOevssc2xZJpBRX19ff2a3OGGG27IxRdfnMmTJzd8rKmqqiqDBg3KqFGjctBBB32ghayYM+MD3Q9Y+7XuNay5lwAUsnL5K+87Z41j4x0rVqzInDlvv/XRrVu3f/qLWcQGfHyJDfj4+r/Exgf+uvJ11lkn66233ge9OwDwCeEbRAGAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDACiqRXMv4B07bn14cy8BKGThVYc39xKAZuTMBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgqBbNvQA+mgYOGZCvHHdwNttq03Tv2S0nfe203Hv7XxuOP/TqxNXe70fnXZ5rf3x9kqRDp/Y5+fxvZuc9dkx9XV3uunViLjpjXN5a8lbD/KG7bpejT/paNtp0wyxftjyPPDA1l5wzPq+9PKvsBuETaq9xt+a1+UtWGT9o8MY5ba+BmbNoaS6+89E8MKMmi5evTL+u7XPkzptl+Oa9G+Y++dqbuWTCY5n26pupqqzI7putn5M+OyBtWr79X87Ts+blF/c9nUdmzsm8JcvSq2Pb/L9BG+XLQz7VZPukaYkNPpDWbVrlmWnP5Zbf3JqxV313leOfGzCi0e0ddxuS0y/6du7+470NY+dddka69eiaEw4elRbrtMiZPxyd08aelDOOPy9J0qvPernwF9/Lr3/y25xxwnlp16FdRp19Qn7w8/PzlT2PLLo/+KS67ojdU1df33B7+uz5Ofa6v2SPzddPkpx+86QsXLoil3xxp3Ru0zK3PT4zp/zugfz6iN2z2XqdM3vhWznm2onZ89N9MvpzA7No+YqMvWNqzrz5oVx44A5JkidnvZnObavz3RHbp2eH1pk6c27O++PDqaqsyMHbbdIs+6YsscEHct/dD+a+ux/8X4/Pff2NRrd32XPnTP7bI3nlpdeSJP022SA77jY0h37uqDz56NNJkgtPvySXXPuD/OjcyzOnZm4227p/qqqq8uPv/yz1f//jd+0V1+fCX3wvVS2qUruyttDu4JOrS9vqRrev+ttT6dO5bQZv0D1JMnXm3Hxn722z1fpdkiRHDds81z74bJ6YNS+brdc5E599LS2qKjN6r4GprKhIkpy+97Y58Cd/zktvLErfLu0yYpsNGz1H787tMvWVNzLhqVfExseUazYorku3ztl59x1y8/V/bBjbavCns2DewobQSJJJf5mcurq6bDlwiyTJU48+k7q6uux78N6prKxM2/Zts9cXPptJf5ksNKAJrKity62PvZT9t+mXir+Hw4A+XXPHEzMz/63lqauvz+2Pz8yylbUNMbJiZV3WqapsCI0kqV6nKknyyMw5/+tzLVq6Ih1btSy4G5qT2KC4fQ76XBYvWpK7b/2f6zi6du+SN+e+2WhebW1tFsxbmK7rvv2K6dWZr2Xkl76V4049Kn974c7c8/Rt6dFr3Yw+5qwmXT98Ut311CtZuHRF9hvQr2HsB18YmpW19dn1wluy/ff+M+ffOjk/PHCH9O3SLkmyXb/umbtoaa6+7+msqK3LgreWZ9yEx5IkcxYuXe3zTJk5J396YmYO2HbD1R7no+9Dj42ZM2fma1/72nvOWbZsWRYsWNDop66+7sNeCmuJ/Q7eO7ff+OcsX7Z8je7XtXuXnDb2lPzxP27PYXsfk6M/PzIrlq/I9396bqGVAu9205QXstMmPbNu+9YNY5ffMy0Lly7PlYcMy3VH7J5DhvTPKb97MM/WzE+SbLJux5y733b51QPPZOiYG7P7xX9Ir85t07VtdSorVn2O6bPn58Tf3pdjdtkiO27cs6m2RhP70GPjjTfeyDXXXPOec8aMGZOOHTs2+nlt0cwPeymsBbbZfuv022SD3PzrPzQan/v6G+nctXOjsaqqqnTo1D5zZ799vceBh38+ixcuyqXnX5FnHn82jzw4NWeOPD/bDxucLbfdosn2AJ9Er85bnAefr8nnB/7P2YaZbyzK9Q89l7P3HZwhG/bIpj075dhdt8ine3XODf/1XMO8vbfqmwmj9s2fvrlP7j1pv3x9ly3y5pJlWb9zu0bP8dzrC3L0tRNzwMCNctSwzZtsbzS9Nb5A9JZbbnnP4zNmzHjfxxg9enRGjRrVaOwzm+69pkvhI2D/L+2TJ6Y+lWefeK7R+GP/NS0dOrXPZlv1z1OPPZMkGbzztqmsrMzjjzyRJGnVulXq6uob3a+29u0zYJWV3gGEkm6e+kK6tG2VYZ/6n7MNS1e8fa3Uu6/HeOf2uz/B8o6u7VolSW6a8nxatqjK0I3WbTg2ffb8HH3txOy79QYZuduWJbbAWmSNY2PEiBGpqKho+HTA6lRUrOZc2btUV1enurrxFc+VFf7z+Chp3aZ1+my4fsPtXn3WS/9Pb5L58xak5pXZSZK27dpk933/JZecM36V+78w/cXcd9cD+c6Fp2TMty9Ki3WqcvL538yfbp6QOTVzkyR/nXB/vnT0gTnyxMNyx00T0qZdmxx/6lF5deZrefrxZ5pmo/AJVFdfn1umvph9t94gLd4V9v26tU+fLu1y/q0P58ThW6dT65a5++lX88CMmow7eKeGedc/ND0DendNm5Ytcv+Mmlxy52P5xu5bpsPfLwCdPnt+jvrVxOy4cY98ZWj/zFn09rUclRUVq3waho+Hivr3qobVWH/99XP55Zdn//33X+3xKVOmZNCgQamtXbNPC2zXa5c1mk/z2naHbXLl78atMv6HG27LOSeOSZJ8/sv7ZtS5I/O5bT6fxQsXrzK3Q6f2Ofm738ywPXb6+5d63ZsLT2/8pV577L9bDj3u39J3o95Z+tayPDZ5Wi797hV5cfpL5TbHh27iD4Y19xJYA/c9NyvH/fqvufm4PbNB1/aNjr04d2HG3fV4Hpk5J0uWr0zfzu1y6A79869bb9Aw5/SbJuUv02dlyfKV2bBr+1WO//jeably4pOrPO96Hdvktm84y/1R0/qQVb9r6R+tcWzst99+2WabbXLuuau/SG/q1KkZOHBg6urW7IJPsQEfX2IDPr7+L7Gxxm+jnHzyyVm8eNVXqe/YZJNNcvfdd6/pwwIAH1NrHBvDhr33K5S2bdtm1113/cALAgA+XlyVCQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFFiAwAoSmwAAEWJDQCgKLEBABQlNgCAosQGAFCU2AAAihIbAEBRYgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFCU2AICixAYAUJTYAACKEhsAQFEV9fX19c29CD5Zli1bljFjxmT06NGprq5u7uUAHyK/36yO2KDJLViwIB07dsz8+fPToUOH5l4O8CHy+83qeBsFAChKbAAARYkNAKAosUGTq66uzllnneXiMfgY8vvN6rhAFAAoypkNAKAosQEAFCU2AICixAYAUJTYoEmNHz8+/fr1S6tWrTJkyJBMmjSpuZcEfAgmTpyYfffdN7169UpFRUVuuumm5l4SaxGxQZO54YYbMmrUqJx11ll5+OGHM2DAgOy5556ZPXt2cy8N+CctXrw4AwYMyPjx45t7KayFfPSVJjNkyJBst912ueyyy5IkdXV16dOnT0aOHJlTTz21mVcHfFgqKipy4403ZsSIEc29FNYSzmzQJJYvX57Jkydn+PDhDWOVlZUZPnx47r///mZcGQCliQ2axJw5c1JbW5sePXo0Gu/Ro0dmzZrVTKsCoCmIDQCgKLFBk+jWrVuqqqpSU1PTaLympiY9e/ZsplUB0BTEBk2iZcuWGTRoUCZMmNAwVldXlwkTJmSHHXZoxpUBUFqL5l4AnxyjRo3KYYcdlsGDB2f77bfPJZdcksWLF+erX/1qcy8N+CctWrQo06dPb7j9/PPPZ8qUKenSpUv69u3bjCtjbeCjrzSpyy67LGPHjs2sWbOyzTbbZNy4cRkyZEhzLwv4J91zzz35zGc+s8r4YYcdlquvvrrpF8RaRWwAAEW5ZgMAKEpsAABFiQ0AoCixAQAUJTYAgKLEBgBQlNgAAIoSGwBAUWIDAChKbAAARYkNAKAosQEAFPXfBgUyEZqg8sUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_shuffled, grid_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7c69864fe6741",
   "metadata": {
    "id": "6ee7c69864fe6741",
    "outputId": "7cfa59b2-b1cc-44b8-b629-8a794b8add8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9580,  420],\n",
       "       [1708, 7892]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d131ca",
   "metadata": {
    "id": "81d131ca"
   },
   "source": [
    "Comparing the two confusion matrices, we can observe the following changes:\n",
    "\n",
    "**Before the hyperparameter search:**\n",
    "\n",
    "- True Negatives (TN): `9559`\n",
    "- False Positives (FP): `441`\n",
    "- False Negatives (FN): `1464`\n",
    "- True Positives (TP): `8136`\n",
    "\n",
    "**After the hyperparameter search:**\n",
    "\n",
    "- True Negatives (TN): `9580`\n",
    "- False Positives (FP): `420`\n",
    "- False Negatives (FN): `1708`\n",
    "- True Positives (TP): `7892`\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- There is a slight improvement in true negatives (TN), increasing from 9559 to 9580.\n",
    "- There is a reduction in false positives (FP), decreasing from 441 to 420.\n",
    "- There is an increase in false negatives (FN), rising from 1464 to 1708.\n",
    "- There is a decrease in true positives (TP), dropping from 8136 to 7892.\n",
    "\n",
    "Therefore, after applying the hyperparameter search, the model tends to correctly classify more samples as non-pedestrians (increase in true negatives) and fewer samples as false positives (decrease in false positives). However, there is also an increase in false negatives, indicating that the model incorrectly classifies more samples as non-pedestrians when they are actually pedestrians. This suggests that the hyperparameter tuning has impacted the model's ability to generalize, but additional adjustments may still be needed to improve performance in terms of pedestrian classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080d13cd7c0100b",
   "metadata": {
    "id": "e080d13cd7c0100b",
    "outputId": "f1bc6c3c-4c18-4eee-beb0-a25c17790b8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.96      0.90     10000\n",
      "         1.0       0.95      0.82      0.88      9600\n",
      "\n",
      "    accuracy                           0.89     19600\n",
      "   macro avg       0.90      0.89      0.89     19600\n",
      "weighted avg       0.90      0.89      0.89     19600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_shuffled, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc4121",
   "metadata": {
    "id": "01cc4121"
   },
   "source": [
    "**Before the hyperparameter search:**\n",
    "\n",
    "- Precision for class 0 (non-pedestrians): `0.87`\n",
    "- Recall for class 0: `0.96`\n",
    "- F1-score for class 0: `0.91`\n",
    "- Precision for class 1 (pedestrians): `0.95`\n",
    "- Recall for class 1: `0.85`\n",
    "- F1-score for class 1: `0.90`\n",
    "- Accuracy: `0.90`\n",
    "\n",
    "**After the hyperparameter search:**\n",
    "\n",
    "- Precision for class 0 (non-pedestrians): `0.85`\n",
    "- Recall for class 0: `0.96`\n",
    "- F1-score for class 0: `0.90`\n",
    "- Precision for class 1 (pedestrians): `0.95`\n",
    "- Recall for class 1: `0.82`\n",
    "- F1-score for class 1: `0.88`\n",
    "- Accuracy: `0.89`\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- After the hyperparameter search, we observe a decrease in recall for class 1 (pedestrians), from 0.85 to 0.82.\n",
    "- There is also a slight decrease in precision for class 0 (non-pedestrians), from 0.87 to 0.85.\n",
    "- The F1-score for class 0 remains relatively stable, decreasing only slightly from 0.91 to 0.90.\n",
    "- The F1-score for class 1 shows a more notable decrease, from 0.90 to 0.88.\n",
    "- The overall accuracy of the model slightly decreases from 0.90 to 0.89 after the hyperparameter search.\n",
    "\n",
    "Therefore, we will choose the initially trained model, which has a better balance in terms of prediction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6285095be5d9575",
   "metadata": {
    "id": "b6285095be5d9575",
    "outputId": "cd60a41e-544f-433a-ebcd-183eb03b080f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predicciones.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo resultante\n",
    "joblib.dump(grid_search, 'modelo_entrenado.pkl')\n",
    "\n",
    "# Realizar predicciones con el modelo y guardarlas\n",
    "grid_predictions = grid_search.predict(X_test_shuffled)\n",
    "joblib.dump(grid_predictions, 'predicciones.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b9621",
   "metadata": {
    "id": "b92b9621"
   },
   "source": "With this last line, we save our model so that it can be used later to generate predictions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f00ee",
   "metadata": {
    "id": "910f00ee"
   },
   "outputs": [],
   "source": [
    "# Cargar el modelo\n",
    "modelo_cargado = joblib.load('modelo_entrenado.pkl')\n",
    "\n",
    "# Cargar las predicciones\n",
    "predicciones_cargadas = joblib.load('predicciones.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
